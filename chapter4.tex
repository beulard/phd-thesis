\chapter{Fake Monte Carlo data generation}
\begin{markdown}
---

- We are coming from the simulation chapter, so:
- Problem description: 
 - We would like to produce larger amounts of simulation data, e.g. for a mock dataset in preparation for data-taking
 - But we have limited capability to produce MC data with simulation. The main bottleneck is in the pion-production section's hadronic interactions. Is there a faster way?
  - The topic of this chapter is to consider the application of machine-learning methods in the fabrication of fake Monte Carlo data.


- Creation of dataset from Monte Carlo simulation
  - Hit pattern characterisation
  - Reconstructible vs noise-like classification
- GAN theory [Goodfellow, WGAN, WGAN-GP]
 - Pre-processing
- GAN design, basic architecture, softmax for classes [WGAN-GP]
- GAN extensions, embedding? analogy with text?

---
\end{markdown}

% Need to wrap the start of this chapter into a compelling narrative:
% 1. MC allows us to see possible patterns in detector sys
%  e.g., in CDC, high-mom tracks produce structured hits whereas low-mom make small 
%  localised hit clusters --> Draw figures
% 2. For an exercise such as a mock-data challenge (explain term),
%  traditional MC is not efficient enough to produce the dataset.
%  + Think about: why do we want mock data? Why is the standard sensitivity estimation
%    process not sufficient?
%    - Perhaps the extrapolation factor. Considering efficiencies on a limited sample cannot
%       effectively be representative of the real situation.
%    - The sheer sample size makes the exercise worth it? Test limits of the data processing
%       chain and increase preparedness for real situation.
% 3. Now consider the problem of producing artificial / fake / imitation / 
%  fictitious / fabricated data.
%  + Consider alternatives
%  + Introduce GAN for detector-level data fabrication.

As discussed in the previous chapter, Monte Carlo simulation allows us to draw a realistic picture of what will happen in our experimental setup once it is running. Most importantly, it provides an estimate of the kinds of patterns we can expect to observe in the detector system. 

When performing a full simulation of COMET Phase-I, most of the activity takes place in the initial collision between the proton beam and the graphite target. The many hadronic interactions caused by the high-energy protons represent \SI{99.7}{\percent} of the computational cost of the Monte Carlo simulation.
In contrast to that, because of the large distance between the pion-production section and the detector area, only one muon will come at rest in the stopping target for around every \num{2000} proton-on-target (POT) collisions. Hence, producing Monte Carlo data in the detector system by simulating POT events one by one is a very inefficient process. Not only is most of the computation time spent in determining how secondaries are produced in the proton collision, but statistically, any one collision only has a probability of \SI{0.12}{\percent} to produce meaningful, observable information in the detector system (i.e.\ hits).
% Calculation of above number on MC5
% We can RooTrackerTree->Draw("StdHepN", "StdHepN>0") to get the number of events with a downstream track, but to get the number of events with a hit, it's a bit more involved...
% We need to use the downstream root files
% MC5A01: StdHepN>0 --> 27267993 / 990678400 ~= 2.75% in all RT files
% ---> 2.75% of all POT events lead to >=1 particle entering the detector region
% Repeat on MC5A02 RT files to get stopped muons per POT
% MC5A02: StdHepN>0 && StdHepPdg==13 --> 486051 / 990678399 ~= 0.049%
% ---> 0.049% of all POT events lead to >=1 stopped muon
% /sps/mc5a02/count_events_with_cdc_hits.C --> 5939 / 4980700 ~= 0.12% in first root file
% /sps/mc5a02/count_events_with_cdc_hits.C --> 1173800 / 990678399 ~= 0.1185% in all dataset
    % Watch job 20862516 output for answer
% ---> 0.12% of all POT events lead to >=1 hits in the CDC
% CORRECTION: we counted events where there are hits even if none of them have edep>0
% --> Only count events where at least one edep>0 hit occurs:
% /sps/mc5a02/count_events_with_cdc_hits_edep.C --> 260 / 4980700 ~= 5.22e-5 in first root file
% in first 10: 2611 / 49468900 ~= 5.278e-5
% extrapolate to all = 52289 / 990678399

On average, simulating a single POT event in the upstream region requires \SI{2.73}{\second}. A single proton bunch contains \num{16000000} protons, which if simulated linearly would take 500 days of computation. The MC5 production ran for around two weeks on 2000 concurrent machines in order to fully simulate 62 bunches, around $1\times10^9$ protons. During the data-taking period for COMET Phase-I, $2\times10^{12}$ bunches, or $1.6\times 10^{19}$ protons, are expected to hit the target. Simulating a similar amount of MC data is simply impossible with the same methods and infrastructure used to produce MC5.

% Why would we want to do that though? Does anyone else do it? Asked Joe
 % Joe says: they only really care about signal MC, MC of just background seems pointless to them...
% Before talking about why it's impossible, we need to bring up the fact that we 
% WANT to get that much data. We need to motivate this...
% Mock-data
% In COMET, one event could make the difference between absence of signal and CLFV discovery.
% Because of the beam transport, it is hard to estimate the kinds background that can enter the detector system.
% -> MC is heavily used to constrain or estimate the rates of various background processes

In order to alleviate this issue, multiple solutions can be considered. One that is currently used in \texttt{SimG4} is to split the simulation into spatial regions, as was described in section~\ref{sec:mc5}. Particles that reach the boundary of the first region are saved and then propagated inside the second region. 

% Reseeding
\hl{RESEEDING}

% Resampling
At the boundary between the regions, we can draw histograms from the position and momentum of particles crossing and later sample from that distribution to generate events in the second region.

Another solution, which we have not yet exploited in COMET, could be to aggressively cut away particles produced in the hadronic interaction which have a small probability of resulting in observable detector hits. To select particles, several options are available such as cuts on position, momentum and particle type, or one could for instance train a more intelligent classifier out of those features.

Lastly, and as is the topic of this chapter, one could partially replace the Monte Carlo simulation by constructing % right word?
a generator which can replicate the patterns of simulated particles in the detectors.

In this chapter, I will discuss my implementation of a Generative Adversarial Networks-based solution to the problem of fast realistic hit generation in the CDC. This restricted application ultimately strives toward a CyDet-wide event sampling algorithm whose lower computational cost compared to traditional Monte Carlo simulation would enable the production of larger datasets, on a scale approaching that of the measurement to be performed.

\section{Data selection} % Name?
% Describe the procedure to go from MC data to fake datasets, can use some math abstraction for the GAN, indicating that it could be something else entirely, e.g. G(z) = fake hits, F(x_i, p_i, PID_i) = real hits, distribution(G(z)) ~ distribution(F(.))
If our aim is to build a generative model to mimic the patterns of hits in the detector, it is necessary to keep in mind that these hits are physical energy deposits created by simulating energy loss processes of particles inside the active detector volume. The true process of producing hits thus obeys very strict rules stemming from the physical laws in play. The model we consider here is purely data-driven in that we do not enforce any awareness of physics onto it. Although this choice makes the potential speed-up significant, it also means that we lose much of our control over the content of produced data and rely on the accuracy of the model to yield physically realistic hits.

In COMET Phase-I, events of particular interest come in the form of extended tracks in the CDC, whose accurate reconstruction (in both momentum and position) is paramount to the identification of a conversion signal. These tracks typically produce hits in very specific patterns, dictated by the particle's exact trajectory and energy loss in the gas. We expect a data-driven generative model to struggle in replicating the exact signature of such tracks, hence we decided early on to restrict the scope of the model to events that lack any physics-rich features. 
% ^ OK


% Consequences: we have to combine MC and GAN data
% ---> means we have to find a way to produce MC selectively
% ---> and then mix hits in realistic proportions to get mock data.

%In addition to the rigid constraints involved in producing tracks, it is preferable from the point of view of the reconstruction algorithms to be able to query their true provenance. A physics-agnostic model is by definition unable to provide that kind of truth information

Not all MC data can be replaced by an alternative algorithm. Monte Carlo simulation has the particularity of providing full truth information about every hit in the detector system, including the type and whereabouts of the particles that produced them.
Truth information is typically useful when a series of hits is susceptible to be reconstructed into a track, whose true provenance will be compared to the guess from the reconstruction algorithm. % Think about this. Is this true? What's the point of reconstruction? Should we consider a hypothetical scenario where we have a dataset with an unknown number of signal tracks and we ask someone to find the needles in the haystack?
% Then why isn't our classification simply signal tracks versus all other tracks?

% Characterisation of tracks in the CDC: high-momentum vs low-momentum
Thankfully, not all hits in the detector require associated truth information, and in fact the majority of hits in the CDC appear like background noise whose origin is irrelevant to any reconstruction procedure. % The question is: DEFINE EXACTLY WHAT KIND OF DATA NEEDS TRUTH
% Illustrate with figure ?
%To illustrate this idea, Fig.~\ref{fig:noise_vs_recon} showcases hits produced by two types of particles.

To define our problem, let us consider the situation where a large quantity of artificial data must be produced but traditional simulation is simply too inefficient to reach the desired sample size.

% ^^^^ Review up to ^OK

\subsection{Hit categorisation}
% This is what hits from p>50MeV tracks look like, and this is what hits from p<50MeV tracks look like.
% From the observation that the former tends to have reconstructible hit patterns while the latter contains single hits and localised patterns, we categorise MC events according to whether they contain a p>50MeV track or not.
% We then use hits from non-reconstructible events as the training data for our generative model whose goal is to learn the patterns and generate original samples of hits that we can use as a background onto which we will overlay reconstructible MC-simulated events.
% The result is the offloading of 99% of the simulation to the generative model which is highly efficient. Since the information generated is 
Fig.~\ref{fig:cdc_rconst_vs_noise} outlines the difference in structure between hits produced by $p\leq\SI{50}{\MeV/\clight}$ tracks~(\ref{fig:cdc_rconst_vs_noise:low}) and hits produced by $p>\SI{50}{\MeV/\clight}$ tracks~(\ref{fig:cdc_rconst_vs_noise:high}) in the CDC. Generally, this loose momentum threshold separates what the detector recognises as prolonged circular tracks from more localised clusters of hits.

\begin{figure}
    \centering
    \begin{subfigure}{0.4\textwidth}
        \centering
        %\includegraphics[width=\textwidth]{example-image}
        \hl{TODO}
        \caption{$p\leq\SI{50}{\MeV/\clight}$}
        \label{fig:cdc_rconst_vs_noise:low}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.4\textwidth}
        \centering
        %\includegraphics[width=\textwidth]{example-image}
        \hl{TODO}
        \caption{$p > \SI{50}{\MeV/\clight}$}
        \label{fig:cdc_rconst_vs_noise:high}
    \end{subfigure}
    \caption{Comparison of hit patterns in the CDC produced by tracks of different momenta.}
    \label{fig:cdc_rconst_vs_noise}
\end{figure}

This observation allows us to define \emph{reconstructible} events as those that induce one or more such high-momentum tracks, while other events can be seen as merely sources of \emph{noise} in the detector. This noise will be the target of our generative model. In fact, more than 97\% of hit-inducing events will contain only such hits, so offloading the simulation of this noise to an efficient generator is certain to make producing larger datasets possible.

% Official MC5A02 calculation: 
% Total events: 990678399
%  Hit classification: 
%  2036 unique events (rate 2e-6) with reconstructible hits (63648 hits)
%  49101 unique events (rate 5e-5) with noiselike hits (634266 hits)




\section{Generative Adversarial Networks}
\hl{rework paragraph}
Generative Adversarial Networks (GAN) are a class of data-driven sampling algorithms through which the underlying distribution of a dataset can be modelled and sampled from to obtain new, original samples~\cite{goodfellow_generative_2014}. % "sample" count: 3 ...
The method consists in simultaneously training two models in an adversarial process [...].

% Training framework for original GAN: minmax formulation etc
Adversarial training of the discriminative and generative models can be described as a zero-sum game where the discriminator must learn to tell the difference between real and fake samples, while the generator aims to fool the discriminator.
For concreteness, let us consider the case where both the discriminator and the generator are artificial neural networks, $D$ and $G$, respectively. $D$ is built as a binary classifier of real and fake samples. Given a sample $\mathbf{x}$, it outputs a score between 0 and 1, i.e.\ $D(\mathbf{x}) \in [0, 1]$. Similar to a classification task, we define the loss function of $D$ as the cross entropy between its prediction and the true label (conventionally, 0 for a fake sample and 1 for a real sample):
\begin{equation}\label{eq:D_loss}
    \mathcal{L}_D = 
    -\mathbb{E}_{\mathbf{x} \sim p} [ \log D(\mathbf{x}) ] -
    \mathbb{E}_{\tilde{\mathbf{x}} \sim g} [ \log( 1 - D(\tilde{\mathbf{x}}) )],
\end{equation}
where $\mathbb{E}$ denotes the expected value or mean, $p$ is the distribution of real samples and $g$ is the distribution of fake samples.
Intuitively, minimising this function means that the discriminator will assign a high score to samples drawn from the training dataset and a low score to samples generated by $G$.

% Ok so we explained the D training process, now for G
The generator produces fake samples by mapping vectors from a latent space into data space. Latent-space vectors $\mathbf{z}$ are sampled according to a prior $p_\mathbf{z}(\mathbf{z})$, typically a multivariate normal distribution for simplicity and speed. The objective of $G$ is to generate samples $\tilde{\mathbf{x}} = G(\mathbf{z} \sim p_\mathbf{z})$ such that $D(\tilde{\mathbf{x}}) \rightarrow 1$. In other words, the generator aims to maximise the second term in Eq.~\ref{eq:D_loss}, and its loss function is
\begin{align*}
    \mathcal{L}_G &=     
    \mathbb{E}_{\tilde{\mathbf{x}} \sim g} [ \log( 1 - D(\tilde{\mathbf{x}}) )]\\
    &= \mathbb{E}_{\mathbf{z} \sim p_\mathbf{z}} [ \log( 1 - D(G(\mathbf{z}) )].
\end{align*}

Combining these minimisation tasks, we obtain the adversarial training objective which allows the generative model to learn a representation of the underlying data distribution:
\begin{equation}\label{eq:GAN}
    \min_G \max_D \quad
    \mathbb{E}_{\mathbf{x} \sim p} [ \log D(\mathbf{x}) ] +
    \mathbb{E}_{\mathbf{z} \sim p_\mathbf{z}} [ \log( 1 - D(G(\mathbf{z}) )].
\end{equation}
Using neural networks allows the task to be tackled with backpropagation and stochastic gradient descent. At every iteration, both networks evaluate the derivative of their respective loss function with respect to their internal weights. The weights are then adjusted slightly toward the direction of largest decrease in the loss.


\subsection{Wasserstein GAN}
% WGAN, WGAN with Gradient Penalty
The original formulation of GAN is notoriously difficult to train due to either non-convergence, instability or mode collapse\footnote{Mode collapse is the situation where $G$ maps every point in the latent space onto the same output, leading to low diversity in the generated samples.}. 
Training a GAN model is highly sensitive to the choice of hyperparameters: learning rate, optimisation algorithm, network architecture. 

The Wasserstein GAN (WGAN) formulation is an attempt to address the stability issues of the original GAN~\cite{arjovsky2017wasserstein}. The authors argue that solving Eq.~\ref{eq:GAN}, which implicitly minimises the Jensen-Shannon divergence between $p$ and $g$, leads to vanishing gradients when the discriminator is too powerful, and thus to unstable training.
Instead, they propose to minimise the Wasserstein-1 distance between $p$ and $g$ because of its superior continuity and differentiability properties. They go on to show that if the discriminator is 1-Lipschitz continuous, then the adversarial training problem can be formulated as:
\begin{equation}
    \min_G \max_D \quad 
        \mathbb{E}_{\mathbf{x} \sim p} \left[ D(\mathbf{x}) \right] - 
        \mathbb{E}_{\mathbf{z} \sim p_\mathbf{z}} \left[ D(G(\mathbf{z})) \right].
\end{equation}

In practice, aside from a change to the loss functions, this method requires that the discriminator be replaced by a ``critic'', so-called because its output is not bounded to $[0, 1]$ and can be better interpreted as a score. In order for $D$ to satisfy the Lipschitz constraint, the authors propose to restrict the magnitude of its weights to a small range, e.g. $[-0.01, 0.01]$.
%explicitly stating that this is not an optimal solution. 

In addition to the superior training stability of this Wasserstein GAN (WGAN) method, it was observed empirically that this formulation does not lead to mode collapse and improves the robustness of the GAN to internal changes to the network architectures.

% WGAN-GP
The same year, another method to enforce the Lipschitz constraint on $D$ was discussed in~\cite{NIPS2017_892c3b1c}, which outlines the shortcomings of weight clipping and instead proposes to constrain the discriminator's gradient.
By definition, a function is 1-Lipschitz if and only if its gradient has norm at most 1 everywhere. Since this is difficult to achieve in practice, the authors suggest a soft constraint on the gradient norm of $D$ using an explicit term in its loss function:
\begin{equation}\label{eq:WGAN-GP}
    \mathcal{L}_D = 
        -\mathbb{E}_{\mathbf{x} \sim p} \left[ D(\mathbf{x}) \right] +
        \mathbb{E}_{\mathbf{z} \sim p_\mathbf{z}} \left[ D(G(\mathbf{z})) \right] +
        \lambda\ \mathbb{E}_{\hat{\mathbf{x}} \sim p_{\hat{\mathbf{x}}}}
            \left[ \big( \left\Vert \nabla_{\hat{\mathbf{x}}}\ D(\hat{\mathbf{x}}) \right\Vert_2 - 1 \big) ^2 \right],
\end{equation}
where the third term is the gradient penalty added to the WGAN loss, and $\lambda$ is the gradient penalty constant, a new hyperparameter. In this term, samples $\hat{\mathbf{x}}$ are drawn from $p_{\hat{\mathbf{x}}}$ by sampling uniformly along straight lines between pairs of points from $p$ and $g$. 

In our experiments, we find that the above WGAN-GP loss provides the most stable training procedure for a variety of network architectures. In addition, it has the significant advantage of making the critic loss more interpretable and overfitting noticeable. As the authors demonstrate, the critic loss should converge to a maximum value over training iterations, while in the case of overfit, the critic losses evaluated on training samples and test samples diverge during training.

% Examples of usage in HEP (see zotero)
\subsection{GAN in High Energy Physics}
In high-energy physics, GANs have been proposed in a variety of experiments to supplement traditional Monte Carlo simulation. 
\hl{Write}

% How do we plan on using this to sample CDC hits? Big brain time
\section{The CDC hit generator}
In our case, we chose to make use of a GAN model to fabricate hits in the CDC.
% Motivate: we bypass the bottleneck and produce data where it is most needed
Hits from non-reconstructible events are selected and extracted to form the training dataset. Each hit is defined by four features: energy deposit, distance of closest approach between the track and wire, timing and position. We represent position by an integer wire index, ranging from 0 to 4986, which receives a different treatment to the other three continuous features.

Training the GAN to generate individual hits is sufficient to model the underlying distributions of the four features, but the generated hits lack coherence. In the training dataset, when multiple hits are produced by a single track, they often occur next to each other in time and space. The GAN model must be allowed to see and process the relationship between consecutive hits for the generated hits to resemble simulated ones. Hence instead of having the model process single hits, it makes sense to feed it sequences of consecutive hits such that temporal information can be processed as well. The architecture of $G$ and $D$ should be allowed to accommodate for this extra dimension.



\subsection{Network architectures}
Both the generator and discriminator are built using one-dimensional convolutional layers.
The convolution kernels move along the temporal dimension, as illustrated in Fig.~\ref{fig:temporal_conv}. 
In this context, the convolution operation is defined as follows:
\begin{equation}
    y_{i} = \sum_{j=1}^{C_\mathrm{in}} \sum_{k=-(K-1)/2}^{(K-1)/2} w_k\ x_{i+k,j} + b,
\end{equation}
where $i$ is the sequence index, $C_\mathrm{in}$ is the number of features\footnote{Also called the number of channels or feature maps.} in the input, $K$ is the kernel size, $w_k$ is the $k$-th element of the kernel, $x$ is the input sequence and $b$ is the bias. The kernel elements $w$ and bias $b$ are learned parameters of the neural network. 
Convolutional layers typically have multiple output channels, each corresponding to a kernel and bias which extract different features from the input.

The fact that the convolution kernel is moved along the sequence means that the network effectively considers the features of multiple consecutive hits at a time. The effective receptive field of the networks, in terms of consecutive hits, increases with the kernel size of the convolutional layers as well as the total number of layers (i.e.\ depth).
\begin{figure}
    \centering
    %\includegraphics{}
    \hl{TODO}
    \caption{Temporal (1D) convolution}
    \label{fig:temporal_conv}
\end{figure}

The discriminator takes as input a sequence of hits of length $L$. Each hit is described by four features: energy deposit, time, distance of closest approach and wire index. The first convolutional layer computes feature maps by sliding its kernels over the hit sequence. A non-linear activation function is applied to the feature maps before passing them on to the next layer. 
In our case, the leaky rectified linear unit, or \texttt{LeakyReLU}~\cite{Maas13rectifiernonlinearities}, is used as the non-linearity.
% ^ Too much detail?

Optionally, convolution kernels can be applied over the sequence with a stride, by moving the kernel by more than one input element to obtain the next output element. This has the effect of producing an output sequence that is shorter than the input sequence. This is often used to allow the network to see the data over increasingly large scales as well as to reduce the number of operations in deeper layers. 

\subsubsection{Residual connections}
\begin{figure}
    \centering
    %\includegraphics{}
    \caption{Residual block.}
    \label{fig:residual_block}
\end{figure}
In order to facilitate gradient flow from the discriminator to the generator and thus speed up training, convolutional layers are promoted to residual blocks~\cite{he2016deep} in both networks. A residual block combines two convolutional layers with a residual connection from the input to the output, allowing the gradients to propagate via two paths, as shown in Fig.~\ref{fig:residual_block}. The output $\mathbf{y}$ of the block can be written as
\begin{equation*}
    \mathbf{y} = \mathcal{F}(\mathbf{x}) + W_s\mathbf{x},
\end{equation*}
where $\mathcal{F}$ represents the convolutions and $W_s$ is a linear dimension-matching operation which brings $\mathbf{x}$ into the same shape as $\mathbf{y}$, if necessary.
    
The critic architecture is shown in full in Fig.~\ref{fig:disc_arch}. It uses \hl{N} residual blocks to extract features from the input hit sequence and outputs a single score following a global pooling operation and a fully-connected linear layer.

\begin{figure}
    \centering
    %\includegraphics{}
    \caption{Architecture of the critic network.}
    \label{fig:disc_arch}
\end{figure}

The generator architecture is shown in Fig.~\ref{fig:gen_arch}.

\begin{figure}
    \centering
    %\includegraphics{}
    \caption{Architecture of the generator network.}
    \label{fig:gen_arch}
\end{figure}

\subsection{Training}

The GAN is trained with the WGAN-GP loss on Nvidia V100 GPUs.
Optimiser: Adam

\subsection{Evaluation}


%%Compared to other methods such as variational auto-encoders (VAE), GAN are able to generate completely original samples.

% Use new MC5 downstream data from MSci to compare GAN-generated and real hits.


% The hit generation rate is X hits/s, whereas a traditional MC simulation starting from the POT collision creates X hits/s. If re-seeding is used to sample particles at the detector region boundary, X hits/s can be produced, so the efficiency gain is about 1e7.
% However the worry is not so much whether or not GANs can yield increase in efficiency (they can), but whether their output respects all the physical properties expected from MC data.

\subsection{\hl{How GAN-generated hits are merged back into a dataset}}



