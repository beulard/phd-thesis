@article{matchev_uncertainties_2020,
	title        = {Uncertainties associated with {GAN}-generated datasets in high energy physics},
	author       = {Matchev, Konstantin T. and Shyamsundar, Prasanth},
	url          = {http://arxiv.org/abs/2002.06307},
	urldate      = {2021-01-12},
	abstract     = {Recently, Generative Adversarial Networks ({GANs}) trained on samples of traditionally simulated collider events have been proposed as a way of generating larger simulated datasets at a reduced computational cost. In this paper we present an argument cautioning against the usage of this method to meet the simulation requirements of an experiment, namely that data generated by a {GAN} cannot statistically be better than the data it was trained on.},
	journaltitle = {{arXiv}:2002.06307 [hep-ex, physics:hep-ph, physics:physics]},
	date         = {2020-05-29},
	langid       = {english},
	eprinttype   = {arxiv},
	eprint       = {2002.06307},
	keywords     = {High Energy Physics - Phenomenology, High Energy Physics - Experiment, Physics - Computational Physics, Physics - Data Analysis, Statistics and Probability},
	file         = {Matchev and Shyamsundar - 2020 - Uncertainties associated with GAN-generated datase.pdf:/home/md618/Zotero/storage/UNZ83PZS/Matchev and Shyamsundar - 2020 - Uncertainties associated with GAN-generated datase.pdf:application/pdf}
}
@inproceedings{NIPS2017_892c3b1c,
	title        = {Improved Training of Wasserstein GANs},
	author       = {Gulrajani, Ishaan and Ahmed, Faruk and Arjovsky, Martin and Dumoulin, Vincent and Courville, Aaron C},
	year         = 2017,
	booktitle    = {Advances in Neural Information Processing Systems},
	publisher    = {Curran Associates, Inc.},
	volume       = 30,
	pages        = {},
	url          = {https://proceedings.neurips.cc/paper/2017/file/892c3b1c6dccd52936e27cbd0ff683d6-Paper.pdf},
	editor       = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett}
}
@article{Kingma2015AdamAM,
	title        = {Adam: A Method for Stochastic Optimization},
	author       = {Diederik P. Kingma and Jimmy Ba},
	year         = 2015,
	journal      = {CoRR},
	volume       = {abs/1412.6980}
}
@article{karras_progressive_2018,
	title        = {Progressive Growing of {GANs} for Improved Quality, Stability, and Variation},
	author       = {Karras, Tero and Aila, Timo and Laine, Samuli and Lehtinen, Jaakko},
	url          = {http://arxiv.org/abs/1710.10196},
	urldate      = {2021-01-12},
	abstract     = {We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly ﬁne details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., {CELEBA} images at 10242. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised {CIFAR}10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating {GAN} results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the {CELEBA} dataset.},
	journaltitle = {{arXiv}:1710.10196 [cs, stat]},
	date         = {2018-02-26},
	langid       = {english},
	eprinttype   = {arxiv},
	eprint       = {1710.10196},
	keywords     = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file         = {Karras et al. - 2018 - Progressive Growing of GANs for Improved Quality, .pdf:/home/md618/Zotero/storage/YX5JFKQD/Karras et al. - 2018 - Progressive Growing of GANs for Improved Quality, .pdf:application/pdf}
}
@inproceedings{he2016deep,
	title        = {Deep residual learning for image recognition},
	author       = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	year         = 2016,
	booktitle    = {Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages        = {770--778}
}
@article{qin_how_2020,
	title        = {How does Lipschitz Regularization Influence {GAN} Training?},
	author       = {Qin, Yipeng and Mitra, Niloy and Wonka, Peter},
	url          = {http://arxiv.org/abs/1811.09567},
	urldate      = {2021-01-12},
	abstract     = {Despite the success of Lipschitz regularization in stabilizing {GAN} training, the exact reason of its effectiveness remains poorly understood. The direct effect of \$K\$-Lipschitz regularization is to restrict the \$L2\$-norm of the neural network gradient to be smaller than a threshold \$K\$ (e.g., \$K=1\$) such that \${\textbackslash}{\textbar}{\textbackslash}nabla f{\textbackslash}{\textbar} {\textbackslash}leq K\$. In this work, we uncover an even more important effect of Lipschitz regularization by examining its impact on the loss function: It degenerates {GAN} loss functions to almost linear ones by restricting their domain and interval of attainable gradient values. Our analysis shows that loss functions are only successful if they are degenerated to almost linear ones. We also show that loss functions perform poorly if they are not degenerated and that a wide range of functions can be used as loss function as long as they are sufficiently degenerated by regularization. Basically, Lipschitz regularization ensures that all loss functions effectively work in the same way. Empirically, we verify our proposition on the {MNIST}, {CIFAR}10 and {CelebA} datasets.},
	journaltitle = {{arXiv}:1811.09567 [cs]},
	date         = {2020-08-25},
	eprinttype   = {arxiv},
	eprint       = {1811.09567},
	keywords     = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file         = {arXiv Fulltext PDF:/home/md618/Zotero/storage/QXNNRHEK/Qin et al. - 2020 - How does Lipschitz Regularization Influence GAN Tr.pdf:application/pdf;arXiv.org Snapshot:/home/md618/Zotero/storage/IG5Y3TYK/1811.html:text/html}
}
@article{xu_modeling_2019,
	title        = {Modeling Tabular data using Conditional {GAN}},
	author       = {Xu, Lei and Skoularidou, Maria and Cuesta-Infante, Alfredo and Veeramachaneni, Kalyan},
	url          = {http://arxiv.org/abs/1907.00503},
	urldate      = {2021-01-12},
	abstract     = {Modeling the probability distribution of rows in tabular data and generating realistic synthetic data is a non-trivial task. Tabular data usually contains a mix of discrete and continuous columns. Continuous columns may have multiple modes whereas discrete columns are sometimes imbalanced making the modeling difficult. Existing statistical and deep neural network models fail to properly model this type of data. We design {TGAN}, which uses a conditional generative adversarial network to address these challenges. To aid in a fair and thorough comparison, we design a benchmark with 7 simulated and 8 real datasets and several Bayesian network baselines. {TGAN} outperforms Bayesian methods on most of the real datasets whereas other deep learning methods could not.},
	journaltitle = {{arXiv}:1907.00503 [cs, stat]},
	date         = {2019-10-27},
	eprinttype   = {arxiv},
	eprint       = {1907.00503},
	keywords     = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file         = {arXiv Fulltext PDF:/home/md618/Zotero/storage/BBJVRSKM/Xu et al. - 2019 - Modeling Tabular data using Conditional GAN.pdf:application/pdf;arXiv.org Snapshot:/home/md618/Zotero/storage/3Y9BLDV2/1907.html:text/html}
}
@article{he_delving_2015,
	title        = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on {ImageNet} Classification},
	shorttitle   = {Delving Deep into Rectifiers},
	author       = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	url          = {http://arxiv.org/abs/1502.01852},
	urldate      = {2021-01-12},
	abstract     = {Rectified activation units (rectifiers) are essential for state-of-the-art neural networks. In this work, we study rectifier neural networks for image classification from two aspects. First, we propose a Parametric Rectified Linear Unit ({PReLU}) that generalizes the traditional rectified unit. {PReLU} improves model fitting with nearly zero extra computational cost and little overfitting risk. Second, we derive a robust initialization method that particularly considers the rectifier nonlinearities. This method enables us to train extremely deep rectified models directly from scratch and to investigate deeper or wider network architectures. Based on our {PReLU} networks ({PReLU}-nets), we achieve 4.94\% top-5 test error on the {ImageNet} 2012 classification dataset. This is a 26\% relative improvement over the {ILSVRC} 2014 winner ({GoogLeNet}, 6.66\%). To our knowledge, our result is the first to surpass human-level performance (5.1\%, Russakovsky et al.) on this visual recognition challenge.},
	journaltitle = {{arXiv}:1502.01852 [cs]},
	date         = {2015-02-06},
	eprinttype   = {arxiv},
	eprint       = {1502.01852},
	keywords     = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence},
	file         = {arXiv Fulltext PDF:/home/md618/Zotero/storage/DIZJ6EBQ/He et al. - 2015 - Delving Deep into Rectifiers Surpassing Human-Lev.pdf:application/pdf;arXiv.org Snapshot:/home/md618/Zotero/storage/ERSNSTRF/1502.html:text/html}
}
@article{fedus_many_2018,
	title        = {Many Paths to Equilibrium: {GANs} Do Not Need to Decrease a Divergence At Every Step},
	shorttitle   = {Many Paths to Equilibrium},
	author       = {Fedus, William and Rosca, Mihaela and Lakshminarayanan, Balaji and Dai, Andrew M. and Mohamed, Shakir and Goodfellow, Ian},
	url          = {http://arxiv.org/abs/1710.08446},
	urldate      = {2021-01-12},
	abstract     = {Generative adversarial networks ({GANs}) are a family of generative models that do not minimize a single training criterion. Unlike other generative models, the data distribution is learned via a game between a generator (the generative model) and a discriminator (a teacher providing training signal) that each minimize their own cost. {GANs} are designed to reach a Nash equilibrium at which each player cannot reduce their cost without changing the other players' parameters. One useful approach for the theory of {GANs} is to show that a divergence between the training distribution and the model distribution obtains its minimum value at equilibrium. Several recent research directions have been motivated by the idea that this divergence is the primary guide for the learning process and that every step of learning should decrease the divergence. We show that this view is overly restrictive. During {GAN} training, the discriminator provides learning signal in situations where the gradients of the divergences between distributions would not be useful. We provide empirical counterexamples to the view of {GAN} training as divergence minimization. Specifically, we demonstrate that {GANs} are able to learn distributions in situations where the divergence minimization point of view predicts they would fail. We also show that gradient penalties motivated from the divergence minimization perspective are equally helpful when applied in other contexts in which the divergence minimization perspective does not predict they would be helpful. This contributes to a growing body of evidence that {GAN} training may be more usefully viewed as approaching Nash equilibria via trajectories that do not necessarily minimize a specific divergence at each step.},
	journaltitle = {{arXiv}:1710.08446 [cs, stat]},
	date         = {2018-02-20},
	eprinttype   = {arxiv},
	eprint       = {1710.08446},
	keywords     = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file         = {arXiv Fulltext PDF:/home/md618/Zotero/storage/CG3ZR985/Fedus et al. - 2018 - Many Paths to Equilibrium GANs Do Not Need to Dec.pdf:application/pdf;arXiv.org Snapshot:/home/md618/Zotero/storage/AUT3VS2T/1710.html:text/html}
}
@article{karras_style-based_2019,
	title        = {A Style-Based Generator Architecture for Generative Adversarial Networks},
	author       = {Karras, Tero and Laine, Samuli and Aila, Timo},
	url          = {http://arxiv.org/abs/1812.04948},
	urldate      = {2021-01-12},
	abstract     = {We propose an alternative generator architecture for generative adversarial networks, borrowing from style transfer literature. The new architecture leads to an automatically learned, unsupervised separation of high-level attributes (e.g., pose and identity when trained on human faces) and stochastic variation in the generated images (e.g., freckles, hair), and it enables intuitive, scale-specific control of the synthesis. The new generator improves the state-of-the-art in terms of traditional distribution quality metrics, leads to demonstrably better interpolation properties, and also better disentangles the latent factors of variation. To quantify interpolation quality and disentanglement, we propose two new, automated methods that are applicable to any generator architecture. Finally, we introduce a new, highly varied and high-quality dataset of human faces.},
	journaltitle = {{arXiv}:1812.04948 [cs, stat]},
	date         = {2019-03-29},
	eprinttype   = {arxiv},
	eprint       = {1812.04948},
	keywords     = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file         = {arXiv Fulltext PDF:/home/md618/Zotero/storage/MWT89ETG/Karras et al. - 2019 - A Style-Based Generator Architecture for Generativ.pdf:application/pdf;arXiv.org Snapshot:/home/md618/Zotero/storage/CEJIG2E5/1812.html:text/html}
}
@article{salimans_improved_2016,
	title        = {Improved Techniques for Training {GANs}},
	author       = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
	url          = {http://arxiv.org/abs/1606.03498},
	urldate      = {2021-01-12},
	abstract     = {We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks ({GANs}) framework. We focus on two applications of {GANs}: semi-supervised learning, and the generation of images that humans find visually realistic. Unlike most work on generative models, our primary goal is not to train a model that assigns high likelihood to test data, nor do we require the model to be able to learn well without using any labels. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on {MNIST}, {CIFAR}-10 and {SVHN}. The generated images are of high quality as confirmed by a visual Turing test: our model generates {MNIST} samples that humans cannot distinguish from real data, and {CIFAR}-10 samples that yield a human error rate of 21.3\%. We also present {ImageNet} samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of {ImageNet} classes.},
	journaltitle = {{arXiv}:1606.03498 [cs]},
	date         = {2016-06-10},
	eprinttype   = {arxiv},
	eprint       = {1606.03498},
	keywords     = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Computer Science - Computer Vision and Pattern Recognition},
	file         = {arXiv Fulltext PDF:/home/md618/Zotero/storage/4LSFHM6R/Salimans et al. - 2016 - Improved Techniques for Training GANs.pdf:application/pdf;arXiv.org Snapshot:/home/md618/Zotero/storage/PVPYXSCB/1606.html:text/html}
}
@inproceedings{7298594,
	title        = {Going deeper with convolutions},
	author       = {Szegedy, Christian and Wei Liu and Yangqing Jia and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
	year         = 2015,
	booktitle    = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	volume       = {},
	number       = {},
	pages        = {1--9},
	doi          = {10.1109/CVPR.2015.7298594}
}
@online{sahoo_residual_2018,
	title        = {Residual blocks — Building blocks of {ResNet}},
	author       = {Sahoo, Sabyasachi},
	url          = {https://towardsdatascience.com/residual-blocks-building-blocks-of-resnet-fd90ca15d6ec},
	urldate      = {2021-01-12},
	abstract     = {Understanding  a residual block is quite easy. In traditional neural networks, each layer feeds into the next layer. In a network with…},
	titleaddon   = {Medium},
	date         = {2018-11-29},
	langid       = {english},
	file         = {Snapshot:/home/md618/Zotero/storage/94FTKW7Q/residual-blocks-building-blocks-of-resnet-fd90ca15d6ec.html:text/html}
}
@article{camino_generating_2018,
	title        = {Generating Multi-Categorical Samples with Generative Adversarial Networks},
	author       = {Camino, Ramiro and Hammerschmidt, Christian and State, Radu},
	url          = {http://arxiv.org/abs/1807.01202},
	urldate      = {2021-01-12},
	abstract     = {We propose a method to train generative adversarial networks on mutivariate feature vectors representing multiple categorical values. In contrast to the continuous domain, where {GAN}-based methods have delivered considerable results, {GANs} struggle to perform equally well on discrete data. We propose and compare several architectures based on multiple (Gumbel) softmax output layers taking into account the structure of the data. We evaluate the performance of our architecture on datasets with different sparsity, number of features, ranges of categorical values, and dependencies among the features. Our proposed architecture and method outperforms existing models.},
	journaltitle = {{arXiv}:1807.01202 [cs, stat]},
	date         = {2018-07-04},
	eprinttype   = {arxiv},
	eprint       = {1807.01202},
	keywords     = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file         = {arXiv Fulltext PDF:/home/md618/Zotero/storage/TVBJ6R94/Camino et al. - 2018 - Generating Multi-Categorical Samples with Generati.pdf:application/pdf;arXiv.org Snapshot:/home/md618/Zotero/storage/4SYPH4LA/1807.html:text/html}
}
@online{bai_comprehensive_2019,
	title        = {A Comprehensive Introduction to Different Types of Convolutions in Deep Learning},
	author       = {Bai, Kunlun},
	url          = {https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215},
	urldate      = {2021-01-12},
	abstract     = {Towards intuitive understanding of convolutions through visualizations},
	titleaddon   = {Medium},
	date         = {2019-02-11},
	langid       = {english}
}
@article{miyato_spectral_2018,
	title        = {Spectral Normalization for Generative Adversarial Networks},
	author       = {Miyato, Takeru and Kataoka, Toshiki and Koyama, Masanori and Yoshida, Yuichi},
	url          = {http://arxiv.org/abs/1802.05957},
	urldate      = {2021-01-12},
	abstract     = {One of the challenges in the study of generative adversarial networks is the instability of its training. In this paper, we propose a novel weight normalization technique called spectral normalization to stabilize the training of the discriminator. Our new normalization technique is computationally light and easy to incorporate into existing implementations. We tested the efficacy of spectral normalization on {CIFAR}10, {STL}-10, and {ILSVRC}2012 dataset, and we experimentally confirmed that spectrally normalized {GANs} ({SN}-{GANs}) is capable of generating images of better or equal quality relative to the previous training stabilization techniques.},
	journaltitle = {{arXiv}:1802.05957 [cs, stat]},
	date         = {2018-02-16},
	eprinttype   = {arxiv},
	eprint       = {1802.05957},
	keywords     = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file         = {arXiv Fulltext PDF:/home/md618/Zotero/storage/IR7ZBE7F/Miyato et al. - 2018 - Spectral Normalization for Generative Adversarial .pdf:application/pdf;arXiv.org Snapshot:/home/md618/Zotero/storage/YTUJFK3I/1802.html:text/html}
}
@inproceedings{wang_multiscale_2003,
	title        = {Multiscale structural similarity for image quality assessment},
	author       = {Wang, Z. and Simoncelli, E.P. and Bovik, A.C.},
	booktitle    = {The Thrity-Seventh Asilomar Conference on Signals, Systems \& Computers, 2003},
	location     = {Pacific Grove, {CA}, {USA}},
	publisher    = {{IEEE}},
	pages        = {1398--1402},
	doi          = {10.1109/ACSSC.2003.1292216},
	isbn         = {978-0-7803-8104-9},
	url          = {http://ieeexplore.ieee.org/document/1292216/},
	urldate      = {2021-01-12},
	abstract     = {The structural similarity image quality paradigm is based on the assumption that the human visual system is highly adapted for extracting structural information from the scene, and therefore a measure of structural similarity can provide a good approximation to perceived image quality. This paper proposes a multi-scale structural similarity method, which supplies more ﬂexibility than previous single-scale methods in incorporating the variations of viewing conditions. We develop an image synthesis method to calibrate the parameters that deﬁne the relative importance of different scales. Experimental comparisons demonstrate the effectiveness of the proposed method.},
	eventtitle   = {Conference Record of the 37th Asilomar Conference on Signals, Systems and Computers},
	date         = 2003,
	langid       = {english},
	file         = {Wang et al. - 2003 - Multiscale structural similarity for image quality.pdf:/home/md618/Zotero/storage/QILE2AAZ/Wang et al. - 2003 - Multiscale structural similarity for image quality.pdf:application/pdf}
}
@article{barua_fcc-gan_2019,
	title        = {{FCC}-{GAN}: A Fully Connected and Convolutional Net Architecture for {GANs}},
	shorttitle   = {{FCC}-{GAN}},
	author       = {Barua, Sukarna and Erfani, Sarah Monazam and Bailey, James},
	url          = {http://arxiv.org/abs/1905.02417},
	urldate      = {2021-01-12},
	abstract     = {Generative Adversarial Networks ({GANs}) are a powerful class of generative models. Despite their successes, the most appropriate choice of a {GAN} network architecture is still not well understood. {GAN} models for image synthesis have adopted a deep convolutional network architecture, which eliminates or minimizes the use of fully connected and pooling layers in favor of convolution layers in the generator and discriminator of {GANs}. In this paper, we demonstrate that a convolution network architecture utilizing deep fully connected layers and pooling layers can be more effective than the traditional convolution-only architecture, and we propose {FCC}-{GAN}, a fully connected and convolutional {GAN} architecture. Models based on our {FCC}-{GAN} architecture learn both faster than the conventional architecture and also generate higher quality of samples. We demonstrate the effectiveness and stability of our approach across four popular image datasets.},
	journaltitle = {{arXiv}:1905.02417 [cs, stat]},
	date         = {2019-05-27},
	eprinttype   = {arxiv},
	eprint       = {1905.02417},
	keywords     = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file         = {arXiv Fulltext PDF:/home/md618/Zotero/storage/FDLP27WC/Barua et al. - 2019 - FCC-GAN A Fully Connected and Convolutional Net A.pdf:application/pdf;arXiv.org Snapshot:/home/md618/Zotero/storage/BC2J6GF4/1905.html:text/html}
}
@online{noauthor_towards_nodate,
	title        = {Towards Data Set Augmentation With {GANs}},
	url          = {https://www.jungle.ai/post/towards-data-set-augmentation-with-gans},
	urldate      = {2021-01-12}
}
@article{deOliveira2017a,
	title        = {Learning Particle Physics by Example: Location-Aware Generative Adversarial Networks for Physics Synthesis},
	author       = {de Oliveira, Luke and Paganini, Michela and Nachman, Benjamin},
	year         = 2017,
	month        = {9},
	journal      = {Computing and Software for Big Science},
	publisher    = {Springer Science and Business Media LLC},
	volume       = 1,
	number       = 1,
	doi          = {10.1007/s41781-017-0004-6},
	issn         = {2510-2044},
	url          = {http://dx.doi.org/10.1007/s41781-017-0004-6}
}
@article{paganini_calogan_2018,
	title        = {{CaloGAN}: Simulating 3D High Energy Particle Showers in Multi-Layer Electromagnetic Calorimeters with Generative Adversarial Networks},
	shorttitle   = {{CaloGAN}},
	author       = {Paganini, Michela and de Oliveira, Luke and Nachman, Benjamin},
	volume       = 97,
	number       = 1,
	pages        = {014021},
	doi          = {10.1103/PhysRevD.97.014021},
	issn         = {2470-0010, 2470-0029},
	url          = {http://arxiv.org/abs/1712.10321},
	urldate      = {2021-01-13},
	abstract     = {The precise modeling of subatomic particle interactions and propagation through matter is paramount for the advancement of nuclear and particle physics searches and precision measurements. The most computationally expensive step in the simulation pipeline of a typical experiment at the Large Hadron Collider ({LHC}) is the detailed modeling of the full complexity of physics processes that govern the motion and evolution of particle showers inside calorimeters. We introduce {\textbackslash}textsc\{{CaloGAN}\}, a new fast simulation technique based on generative adversarial networks ({GANs}). We apply these neural networks to the modeling of electromagnetic showers in a longitudinally segmented calorimeter, and achieve speedup factors comparable to or better than existing full simulation techniques on {CPU} (\$100{\textbackslash}times\$-\$1000{\textbackslash}times\$) and even faster on {GPU} (up to \${\textbackslash}sim10{\textasciicircum}5{\textbackslash}times\$). There are still challenges for achieving precision across the entire phase space, but our solution can reproduce a variety of geometric shower shape properties of photons, positrons and charged pions. This represents a significant stepping stone toward a full neural network-based detector simulation that could save significant computing time and enable many analyses now and in the future.},
	journaltitle = {Physical Review D},
	shortjournal = {Phys. Rev. D},
	date         = {2018-01-30},
	langid       = {english},
	eprinttype   = {arxiv},
	eprint       = {1712.10321},
	keywords     = {High Energy Physics - Phenomenology, High Energy Physics - Experiment, Computer Science - Machine Learning, Statistics - Machine Learning},
	file         = {Paganini et al. - 2018 - CaloGAN Simulating 3D High Energy Particle Shower.pdf:/home/md618/Zotero/storage/XEJQVCNE/Paganini et al. - 2018 - CaloGAN Simulating 3D High Energy Particle Shower.pdf:application/pdf}
}
@article{Erdmann2019,
	title        = {Precise Simulation of Electromagnetic Calorimeter Showers Using a Wasserstein Generative Adversarial Network},
	author       = {Erdmann, Martin and Glombitza, Jonas and Quast, Thorben},
	year         = 2019,
	month        = {1},
	day          = 14,
	journal      = {Computing and Software for Big Science},
	volume       = 3,
	number       = 1,
	pages        = 4,
	doi          = {10.1007/s41781-018-0019-7},
	issn         = {2510-2044},
	url          = {https://doi.org/10.1007/s41781-018-0019-7},
	abstract     = {Simulations of particle showers in calorimeters are computationally time-consuming, as they have to reproduce both energy depositions and their considerable fluctuations. A new approach to ultra-fast simulations is generative models where all calorimeter energy depositions are generated simultaneously. We use GEANT4 simulations of an electron beam impinging on a multi-layer electromagnetic calorimeter for adversarial training of a generator network and a critic network guided by the Wasserstein distance. The generator is constrained during the training such that the generated showers show the expected dependency on the initial energy and the impact position. It produces realistic calorimeter energy depositions, fluctuations and correlations which we demonstrate in distributions of typical calorimeter observables. In most aspects, we observe that generated calorimeter showers reach the level of showers as simulated with the GEANT4 program.}
}
@article{otten_event_2019,
	title        = {Event Generation and Statistical Sampling for Physics with Deep Generative Models and a Density Information Buffer},
	author       = {Otten, Sydney and Caron, Sascha and de Swart, Wieske and van Beekveld, Melissa and Hendriks, Luc and van Leeuwen, Caspar and Podareanu, Damian and de Austri, Roberto Ruiz and Verheyen, Rob},
	url          = {http://arxiv.org/abs/1901.00875},
	urldate      = {2021-01-13},
	abstract     = {We present a study for the generation of events from a physical process with deep generative models. The simulation of physical processes requires not only the production of physical events, but also to ensure these events occur with the correct frequencies. We investigate the feasibility of learning the event generation and the frequency of occurrence with Generative Adversarial Networks ({GANs}) and Variational Autoencoders ({VAEs}) to produce events like Monte Carlo generators. We study three processes: a simple two-body decay, the processes \$e{\textasciicircum}+e{\textasciicircum}-{\textbackslash}to Z {\textbackslash}to l{\textasciicircum}+l{\textasciicircum}-\$ and \$p p {\textbackslash}to t{\textbackslash}bar\{t\} \$ including the decay of the top quarks and a simulation of the detector response. We find that the tested {GAN} architectures and the standard {VAE} are not able to learn the distributions precisely. By buffering density information of encoded Monte Carlo events given the encoder of a {VAE} we are able to construct a prior for the sampling of new events from the decoder that yields distributions that are in very good agreement with real Monte Carlo events and are generated several orders of magnitude faster. Applications of this work include generic density estimation and sampling, targeted event generation via a principal component analysis of encoded ground truth data, anomaly detection and more efficient importance sampling, e.g. for the phase space integration of matrix elements in quantum field theories.},
	journaltitle = {{arXiv}:1901.00875 [hep-ex, physics:hep-ph, physics:physics]},
	date         = {2019-12-04},
	langid       = {english},
	eprinttype   = {arxiv},
	eprint       = {1901.00875},
	keywords     = {High Energy Physics - Phenomenology, High Energy Physics - Experiment, Physics - Data Analysis, Statistics and Probability},
	file         = {Otten et al. - 2019 - Event Generation and Statistical Sampling for Phys.pdf:/home/md618/Zotero/storage/9F3FXURZ/Otten et al. - 2019 - Event Generation and Statistical Sampling for Phys.pdf:application/pdf}
}
@online{noauthor_what_nodate,
	title        = {What are temporal convolutional neural networks?},
	url          = {https://www.quora.com/What-are-temporal-convolutional-neural-networks},
	urldate      = {2021-01-15},
	abstract     = {
		Answer: Temporal Convolutional Networks, or simply {TCN} is a variation over Convolutional Neural Networks for sequence modelling tasks. Rather, it’s quite a descriptive term for a family of architectures.

		Motivation:

		* {TCNs} exhibit longer memory than recurrent architectures with the same capaci...
	},
	titleaddon   = {Quora},
	langid       = {english},
	file         = {Snapshot:/home/md618/Zotero/storage/SILS4YTB/What-are-temporal-convolutional-neural-networks.html:text/html}
}
@article{choi_generating_2018,
	title        = {Generating Multi-label Discrete Patient Records using Generative Adversarial Networks},
	author       = {Choi, Edward and Biswal, Siddharth and Malin, Bradley and Duke, Jon and Stewart, Walter F. and Sun, Jimeng},
	url          = {http://arxiv.org/abs/1703.06490},
	urldate      = {2021-01-19},
	abstract     = {Access to electronic health record ({EHR}) data has motivated computational advances in medical research. However, various concerns, particularly over privacy, can limit access to and collaborative use of {EHR} data. Sharing synthetic {EHR} data could mitigate risk.},
	journaltitle = {{arXiv}:1703.06490 [cs]},
	date         = {2018-01-11},
	langid       = {english},
	eprinttype   = {arxiv},
	eprint       = {1703.06490},
	keywords     = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file         = {Choi et al. - 2018 - Generating Multi-label Discrete Patient Records us.pdf:/home/md618/Zotero/storage/D9ILUI9N/Choi et al. - 2018 - Generating Multi-label Discrete Patient Records us.pdf:application/pdf}
}
@article{brenninkmeijer_generation_nodate,
	title        = {On the Generation and Evaluation of Tabular Data using {GANs}},
	author       = {Brenninkmeijer, Bauke},
	pages        = 70,
	langid       = {english},
	file         = {Brenninkmeijer - On the Generation and Evaluation of Tabular Data u.pdf:/home/md618/Zotero/storage/3GK5DWGL/Brenninkmeijer - On the Generation and Evaluation of Tabular Data u.pdf:application/pdf}
}
@online{noauthor_neural_nodate,
	title        = {neural network - Gumbel-Softmax trick vs Softmax with temperature},
	url          = {https://datascience.stackexchange.com/questions/58376/gumbel-softmax-trick-vs-softmax-with-temperature},
	urldate      = {2021-01-20},
	titleaddon   = {Data Science Stack Exchange}
}
@article{kurach_large-scale_nodate,
	title        = {A Large-Scale Study on Regularization and Normalization in {GANs}},
	author       = {Kurach, Karol and Lucic, Mario and Zhai, Xiaohua and Michalski, Marcin and Gelly, Sylvain},
	pages        = 10,
	abstract     = {Generative adversarial networks ({GANs}) are a class of deep generative models which aim to learn a target distribution in an unsupervised fashion. While they were successfully applied to many problems, training a {GAN} is a notoriously challenging task and requires a signiﬁcant number of hyperparameter tuning, neural architecture engineering, and a non-trivial amount of “tricks”. The success in many practical applications coupled with the lack of a measure to quantify the failure modes of {GANs} resulted in a plethora of proposed losses, regularization and normalization schemes, as well as neural architectures. In this work we take a sober view of the current state of {GANs} from a practical perspective. We discuss and evaluate common pitfalls and reproducibility issues, open-source our code on Github, and provide pre-trained models on {TensorFlow} Hub.},
	langid       = {english},
	file         = {Kurach et al. - A Large-Scale Study on Regularization and Normaliz.pdf:/home/md618/Zotero/storage/MSAF4BNE/Kurach et al. - A Large-Scale Study on Regularization and Normaliz.pdf:application/pdf}
}
@article{buhmann_getting_2020,
	title        = {Getting High: High Fidelity Simulation of High Granularity Calorimeters with High Speed},
	shorttitle   = {Getting High},
	author       = {Buhmann, Erik and Diefenbacher, Sascha and Eren, Engin and Gaede, Frank and Kasieczka, Gregor and Korol, Anatolii and Krüger, Katja},
	url          = {http://arxiv.org/abs/2005.05334},
	urldate      = {2021-01-23},
	abstract     = {Accurate simulation of physical processes is crucial for the success of modern particle physics. However, simulating the development and interaction of particle showers with calorimeter detectors is a time consuming process and drives the computing needs of large experiments at the {LHC} and future colliders. Recently, generative machine learning models based on deep neural networks have shown promise in speeding up this task by several orders of magnitude. We investigate the use of a new architecture — the Bounded Information Bottleneck Autoencoder — for modelling electromagnetic showers in the central region of the {SiliconTungsten} calorimeter of the proposed International Large Detector. Combined with a novel second post-processing network, this approach achieves an accurate simulation of diﬀerential distributions including for the ﬁrst time the shape of the minimum-ionizing-particle peak compared to a full {GEANT}4 simulation for a highgranularity calorimeter with 27k simulated channels. The results are validated by comparing to established architectures. Our results further strengthen the case of using generative networks for fast simulation and demonstrate that physically relevant diﬀerential distributions can be described with high accuracy.},
	journaltitle = {{arXiv}:2005.05334 [hep-ex, physics:hep-ph, physics:physics]},
	date         = {2020-07-20},
	langid       = {english},
	eprinttype   = {arxiv},
	eprint       = {2005.05334},
	keywords     = {High Energy Physics - Phenomenology, High Energy Physics - Experiment, Physics - Data Analysis, Statistics and Probability, Physics - Instrumentation and Detectors},
	file         = {Buhmann et al. - 2020 - Getting High High Fidelity Simulation of High Gra.pdf:/home/md618/Zotero/storage/HVBARYFF/Buhmann et al. - 2020 - Getting High High Fidelity Simulation of High Gra.pdf:application/pdf}
}
@article{loshchilov_decoupled_2019,
	title        = {Decoupled Weight Decay Regularization},
	author       = {Loshchilov, Ilya and Hutter, Frank},
	url          = {http://arxiv.org/abs/1711.05101},
	urldate      = {2021-01-23},
	abstract     = {L\$\_2\$ regularization and weight decay regularization are equivalent for standard stochastic gradient descent (when rescaled by the learning rate), but as we demonstrate this is {\textbackslash}emph\{not\} the case for adaptive gradient algorithms, such as Adam. While common implementations of these algorithms employ L\$\_2\$ regularization (often calling it "weight decay" in what may be misleading due to the inequivalence we expose), we propose a simple modification to recover the original formulation of weight decay regularization by {\textbackslash}emph\{decoupling\} the weight decay from the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard {SGD} and Adam and (ii) substantially improves Adam's generalization performance, allowing it to compete with {SGD} with momentum on image classification datasets (on which it was previously typically outperformed by the latter). Our proposed decoupled weight decay has already been adopted by many researchers, and the community has implemented it in {TensorFlow} and {PyTorch}; the complete source code for our experiments is available at https://github.com/loshchil/{AdamW}-and-{SGDW}},
	journaltitle = {{arXiv}:1711.05101 [cs, math]},
	date         = {2019-01-04},
	eprinttype   = {arxiv},
	eprint       = {1711.05101},
	keywords     = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Optimization and Control},
	file         = {arXiv Fulltext PDF:/home/md618/Zotero/storage/2YN6GH9Q/Loshchilov and Hutter - 2019 - Decoupled Weight Decay Regularization.pdf:application/pdf;arXiv.org Snapshot:/home/md618/Zotero/storage/DL9L6LCL/1711.html:text/html}
}
@article{cote_synthesizing_2020,
	title        = {Synthesizing Property \& Casualty Ratemaking Datasets using Generative Adversarial Networks},
	author       = {Cote, Marie-Pier and Hartman, Brian and Mercier, Olivier and Meyers, Joshua and Cummings, Jared and Harmon, Elijah},
	url          = {http://arxiv.org/abs/2008.06110},
	urldate      = {2021-01-24},
	abstract     = {Due to conﬁdentiality issues, it can be diﬃcult to access or share interesting datasets for methodological development in actuarial science, or other ﬁelds where personal data are important. We show how to design three diﬀerent types of generative adversarial networks ({GANs}) that can build a synthetic insurance dataset from a conﬁdential original dataset. The goal is to obtain synthetic data that no longer contains sensitive information but still has the same structure as the original dataset and retains the multivariate relationships. In order to adequately model the speciﬁc characteristics of insurance data, we use {GAN} architectures adapted for multi-categorical data: a Wassertein {GAN} with gradient penalty ({MC}-{WGAN}-{GP}), a conditional tabular {GAN} ({CTGAN}) and a Mixed Numerical and Categorical Diﬀerentially Private {GAN} ({MNCDP}-{GAN}). For transparency, the approaches are illustrated using a public dataset, the French motor third party liability data. We compare the three diﬀerent {GANs} on various aspects: ability to reproduce the original data structure and predictive models, privacy, and ease of use. We ﬁnd that the {MC}-{WGAN}-{GP} synthesizes the best data, the {CTGAN} is the easiest to use, and the {MNCDP}-{GAN} guarantees diﬀerential privacy.},
	journaltitle = {{arXiv}:2008.06110 [cs, stat]},
	date         = {2020-08-13},
	langid       = {english},
	eprinttype   = {arxiv},
	eprint       = {2008.06110},
	keywords     = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file         = {Cote et al. - 2020 - Synthesizing Property & Casualty Ratemaking Datase.pdf:/home/md618/Zotero/storage/YL5GZ9BL/Cote et al. - 2020 - Synthesizing Property & Casualty Ratemaking Datase.pdf:application/pdf}
}
@article{goodfellow_generative_2014,
	title        = {Generative Adversarial Networks},
	author       = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	url          = {http://arxiv.org/abs/1406.2661},
	urldate      = {2021-01-25},
	abstract     = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
	journaltitle = {{arXiv}:1406.2661 [cs, stat]},
	date         = {2014-06-10},
	langid       = {english},
	eprinttype   = {arxiv},
	eprint       = {1406.2661},
	keywords     = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file         = {Goodfellow et al. - 2014 - Generative Adversarial Networks.pdf:/home/md618/Zotero/storage/CZCT6NSX/Goodfellow et al. - 2014 - Generative Adversarial Networks.pdf:application/pdf}
}
@article{ahdida_fast_2019,
	title        = {Fast simulation of muons produced at the {SHiP} experiment using Generative Adversarial Networks},
	author       = {Ahdida, C. and Albanese, R. and Alexandrov, A. and Anokhina, A. and Aoki, S. and Arduini, G. and Atkin, E. and Azorskiy, N. and Back, J.J. and Bagulya, A. and Santos, F. Baaltasar Dos and Baranov, A. and Bardou, F. and Barker, G.J. and Battistin, M. and Bauche, J. and Bay, A. and Bayliss, V. and Bencivenni, G. and Berdnikov, A.Y. and Berdnikov, Y.A. and Berezkina, I. and Bertani, M. and Betancourt, C. and Bezshyiko, I. and Bezshyyko, O. and Bick, D. and Bieschke, S. and Blanco, A. and Boehm, J. and Bogomilov, M. and Bondarenko, K. and Bonivento, W.M. and Borburgh, J. and Boyarsky, A. and Brenner, R. and Breton, D. and Brundler, R. and Bruschi, M. and Büscher, V. and Buonaura, A. and Buontempo, S. and Cadeddu, S. and Calcaterra, A. and Calviani, M. and Campanelli, M. and Casolino, M. and Charitonidis, N. and Chau, P. and Chauveau, J. and Chepurnov, A. and Chernyavskiy, M. and Choi, K.-Y. and Chumakov, A. and Ciambrone, P. and Congedo, L. and Cornelis, K. and Cristinziani, M. and Crupano, A. and Dallavalle, G.M. and Datwyler, A. and D'Ambrosio, N. and D'Appollonio, G. and Saraiva, J. De Carvalho and Lellis, G. De and de Magistris, M. and Roeck, A. De and Serio, M. De and Simone, D. De and Dedenko, L. and Dergachev, P. and Crescenzo, A. Di and Marco, N. Di and Dib, C. and Dijkstra, H. and Dipinto, P. and Dmitrenko, V. and Dmitrievskiy, S. and Dougherty, L.A. and Dolmatov, A. and Domenici, D. and Donskov, S. and Drohan, V. and Dubreuil, A. and Ehlert, M. and Enik, T. and Etenko, A. and Fabbri, F. and Fabbri, L. and Fabich, A. and Fedin, O. and Fedotovs, F. and Felici, G. and Ferro-Luzzi, M. and Filippov, K. and Fini, R.A. and Fonte, P. and Franco, C. and Fraser, M. and Fresa, R. and Froeschl, R. and Fukuda, T. and Galati, G. and Gall, J. and Gatignon, L. and Gavrilov, G. and Gentile, V. and Gerlach, S. and Goddard, B. and Golinka-Bezshyyko, L. and Golovatiuk, A. and Golubkov, D. and Golutvin, A. and Gorbounov, P. and Gorbunov, D. and Gorbunov, S. and Gorkavenko, V. and Gornushkin, Y. and Gorshenkov, M. and Grachev, V. and Grandchamp, A.L. and Granich, G. and Graverini, E. and Grenard, J.-L. and Grenier, D. and Grichine, V. and Gruzinskii, N. and Guler, A. M. and Guz, Yu. and Haefeli, G.J. and Hagner, C. and Hakobyan, H. and Harris, I.W. and Herwijnen, E. van and Hessler, C. and Hollnagel, A. and Hosseini, B. and Hushchyn, M. and Iaselli, G. and Iuliano, A. and Ivantchenko, V. and Jacobsson, R. and Joković, D. and Jonker, M. and Kadenko, I. and Kain, V. and Kaiser, B. and Kamiscioglu, C. and Kershaw, K. and Khabibullin, M. and Khalikov, E. and Khaustov, G. and Khoriauli, G. and Khotyantsev, A. and Kim, S.H. and Kim, Y.G. and Kim, V. and Kitagawa, N. and Ko, J.-W. and Kodama, K. and Kolesnikov, A. and Kolev, D.I. and Kolosov, V. and Komatsu, M. and Kondrateva, N. and Kono, A. and Konovalova, N. and Kormannshaus, S. and Korol, I. and Korol'ko, I. and Korzenev, A. and Kostyukhin, V. and Platia, E. Koukovini and Kovalenko, S. and Krasilnikova, I. and Kudenko, Y. and Kurbatov, E. and Kurbatov, P. and Kurochka, V. and Kuznetsova, E. and Lacker, H.M. and Lamont, M. and Lanfranchi, G. and Lantwin, O. and Lauria, A. and Lee, K.S. and Lee, K.Y. and Lévy, J.-M. and Loschiavo, V.P. and Lopes, L. and Sola, E. Lopez and Lyubovitskij, V. and Maalmi, J. and Magnan, A. and Maleev, V. and Malinin, A. and Manabe, Y. and Managadze, A.K. and Manfredi, M. and Marsh, S. and Marshall, A.M. and Mefodev, A. and Mermod, P. and Miano, A. and Mikado, S. and Mikhaylov, Yu. and Milstead, D.A. and Mineev, O. and Montanari, A. and Montesi, M.C. and Morishima, K. and Movchan, S. and Muttoni, Y. and Naganawa, N. and Nakamura, M. and Nakano, T. and Nasybulin, S. and Ninin, P. and Nishio, A. and Novikov, A. and Obinyakov, B. and Ogawa, S. and Okateva, N. and Opitz, B. and Osborne, J. and Ovchynnikov, M. and Owtscharenko, N. and Owen, P.H. and Pacholek, P. and Paoloni, A. and Park, B.D. and Park, S.K. and Pastore, A. and Patel, M. and Pereyma, D. and Perillo-Marcone, A. and Petkov, G.L. and Petridis, K. and Petrov, A. and Podgrudkov, D. and Poliakov, V. and Polukhina, N. and Prieto, J. Prieto and Prokudin, M. and Prota, A. and Quercia, A. and Rademakers, A. and Rakai, A. and Ratnikov, F. and Rawlings, T. and Redi, F. and Ricciardi, S. and Rinaldesi, M. and Rodin, Volodymyr and Rodin, Viktor and Robbe, P. and Cavalcante, A.B. Rodrigues and Roganova, T. and Rokujo, H. and Rosa, G. and Rovelli, T. and Ruchayskiy, O. and Ruf, T. and Samoylenko, V. and Samsonov, V. and Galan, F. Sanchez and Diaz, P. Santos and Ull, A. Sanz and Saputi, A. and Sato, O. and Savchenko, E.S. and Schliwinski, J.S. and Schmidt-Parzefall, W. and Serra, N. and Sgobba, S. and Shadura, O. and Shakin, A. and Shaposhnikov, M. and Shatalov, P. and Shchedrina, T. and Shchutska, L. and Shevchenko, V. and Shibuya, H. and Shihora, L. and Shirobokov, S. and Shustov, A. and Silverstein, S.B. and Simone, S. and Simoniello, R. and Skorokhvatov, M. and Smirnov, S. and Sohn, J.Y. and Sokolenko, A. and Solodko, E. and Starkov, N. and Stoel, L. and Storaci, B. and Stramaglia, M.E. and Sukhonos, D. and Suzuki, Y. and Takahashi, S. and Tastet, J.L. and Teterin, P. and Naing, S. Than and Timiryasov, I. and Tioukov, V. and Tommasini, D. and Torii, M. and Tosi, N. and Treille, D. and Tsenov, R. and Ulin, S. and Ustyuzhanin, A. and Uteshev, Z. and Vankova-Kirilova, G. and Vannucci, F. and Venkova, P. and Venturi, V. and Vilchinski, S. and Villa, M. and Vincke, Heinz and Vincke, Helmut and Visone, C. and Vlasik, K. and Volkov, A. and Voronkov, R. and Waasen, S. van and Wanke, R. and Wertelaers, P. and Woo, J.-K. and Wurm, M. and Xella, S. and Yilmaz, D. and Yilmazer, A.U. and Yoon, C.S. and Zarubin, P. and Zarubina, I. and Zaytsev, Yu.},
	volume       = 14,
	number       = 11,
	pages        = {P11028--P11028},
	doi          = {10.1088/1748-0221/14/11/P11028},
	issn         = {1748-0221},
	url          = {https://iopscience.iop.org/article/10.1088/1748-0221/14/11/P11028},
	urldate      = {2021-01-25},
	journaltitle = {Journal of Instrumentation},
	shortjournal = {J. Inst.},
	date         = {2019-11-27},
	langid       = {english},
	file         = {Ahdida et al. - 2019 - Fast simulation of muons produced at the SHiP expe.pdf:/home/md618/Zotero/storage/ZZK3DMJG/Ahdida et al. - 2019 - Fast simulation of muons produced at the SHiP expe.pdf:application/pdf}
}
@article{butter_how_2019,
	title        = {{How to GAN LHC Events}},
	author       = {Anja Butter and Tilman Plehn and Ramon Winterhalder},
	year         = 2019,
	journal      = {SciPost Phys.},
	publisher    = {SciPost},
	volume       = 7,
	pages        = 75,
	doi          = {10.21468/SciPostPhys.7.6.075},
	url          = {https://scipost.org/10.21468/SciPostPhys.7.6.075},
	issue        = 6
}
@article{butter_how_2020,
	title        = {{How to GAN Event Subtraction}},
	author       = {Anja Butter and Tilman Plehn and Ramon Winterhalder},
	year         = 2020,
	journal      = {SciPost Phys. Core},
	publisher    = {SciPost},
	volume       = 3,
	pages        = 9,
	doi          = {10.21468/SciPostPhysCore.3.2.009},
	url          = {https://scipost.org/10.21468/SciPostPhysCore.3.2.009},
	issue        = 2
}
@misc{hashemi2019lhc,
	title        = {LHC analysis-specific datasets with Generative Adversarial Networks},
	author       = {Bobak Hashemi and Nick Amin and Kaustuv Datta and Dominick Olivito and Maurizio Pierini},
	year         = 2019,
	eprint       = {1901.05282},
	archiveprefix = {arXiv},
	primaryclass = {hep-ex}
}
@article{kendrick_anysize_2020,
	title        = {Anysize {GAN}: A solution to the image-warping problem},
	shorttitle   = {Anysize {GAN}},
	author       = {Kendrick, Connah and Gillespie, David and Yap, Moi Hoon},
	url          = {http://arxiv.org/abs/2003.03233},
	urldate      = {2021-01-28},
	abstract     = {We propose a new type of General Adversarial Network ({GAN}) to resolve a common issue with Deep Learning. We develop a novel architecture that can be applied to existing latent vector based {GAN} structures that allows them to generate on-the-ﬂy images of any size. Existing {GAN} for image generation requires uniform images of matching dimensions. However, publicly available datasets, such as {ImageNet} contain thousands of diﬀerent sizes. Resizing image causes deformations and changing the image data, whereas as our network does not require this preprocessing step. We make signiﬁcant changes to the standard data loading techniques to enable any size image to be loaded for training. We also modify the network in two ways, by adding multiple inputs and a novel dynamic resizing layer. Finally we make adjustments to the discriminator to work on multiple resolutions. These changes can allow multiple resolution datasets to be trained on without any resizing, if memory allows. We validate our results on the {ISIC} 2019 skin lesion dataset. We demonstrate our method can successfully generate realistic images at diﬀerent sizes without issue, preserving and understanding spatial relationships, while maintaining feature relationships. We will release the source codes upon paper acceptance.},
	journaltitle = {{arXiv}:2003.03233 [cs, eess]},
	date         = {2020-07-08},
	langid       = {english},
	eprinttype   = {arxiv},
	eprint       = {2003.03233},
	keywords     = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
	file         = {Kendrick et al. - 2020 - Anysize GAN A solution to the image-warping probl.pdf:/home/md618/Zotero/storage/RG52SGUI/Kendrick et al. - 2020 - Anysize GAN A solution to the image-warping probl.pdf:application/pdf}
}
@article{musella_fast_2018,
	title        = {Fast and accurate simulation of particle detectors using generative adversarial networks},
	author       = {Musella, Pasquale and Pandolfi, Francesco},
	volume       = 2,
	number       = 1,
	pages        = 8,
	doi          = {10.1007/s41781-018-0015-y},
	issn         = {2510-2036, 2510-2044},
	url          = {http://arxiv.org/abs/1805.00850},
	urldate      = {2021-01-28},
	abstract     = {Deep generative models parametrised by neural networks have recently started to provide accurate results in modeling natural images. In particular, generative adversarial networks provide an unsupervised solution to this problem. In this work we apply this kind of technique to the simulation of particle-detector response to hadronic jets. We show that deep neural networks can achieve high-ﬁdelity in this task, while attaining a speed increase of several orders of magnitude with respect to traditional algorithms.},
	journaltitle = {Computing and Software for Big Science},
	shortjournal = {Comput Softw Big Sci},
	date         = {2018-11},
	langid       = {english},
	eprinttype   = {arxiv},
	eprint       = {1805.00850},
	keywords     = {High Energy Physics - Phenomenology, High Energy Physics - Experiment, Physics - Data Analysis, Statistics and Probability},
	file         = {Musella and Pandolfi - 2018 - Fast and accurate simulation of particle detectors.pdf:/home/md618/Zotero/storage/I4GD2UMW/Musella and Pandolfi - 2018 - Fast and accurate simulation of particle detectors.pdf:application/pdf}
}
@article{Erdmann2018,
	title        = {Generating and Refining Particle Detector Simulations Using the Wasserstein Distance in Adversarial Networks},
	author       = {Erdmann, Martin and Geiger, Lukas and Glombitza, Jonas and Schmidt, David},
	year         = 2018,
	month        = {7},
	day          = {09},
	journal      = {Computing and Software for Big Science},
	volume       = 2,
	number       = 1,
	pages        = 4,
	doi          = {10.1007/s41781-018-0008-x},
	issn         = {2510-2044},
	url          = {https://doi.org/10.1007/s41781-018-0008-x},
	abstract     = {We use adversarial network architectures together with the Wasserstein distance to generate or refine simulated detector data. The data reflect two-dimensional projections of spatially distributed signal patterns with a broad spectrum of applications. As an example, we use an observatory to detect cosmic ray-induced air showers with a ground-based array of particle detectors. First we investigate a method of generating detector patterns with variable signal strengths while constraining the primary particle energy. We then present a technique to refine simulated time traces of detectors to match corresponding data distributions. With this method we demonstrate that training a deep network with refined data-like signal traces leads to a more precise energy reconstruction of data events compared to training with the originally simulated traces.}
}
@article{the_comet_collaboration_comet_2020,
	title        = {{COMET} Phase-I technical design report},
	author       = {{The COMET Collaboration} and Abramishvili, R and Adamov, G and Akhmetshin, R R and Allin, A and Angélique, J C and Anishchik, V and Aoki, M and Aznabayev, D and Bagaturia, I and Ban, G and Ban, Y and Bauer, D and Baygarashev, D and Bondar, A E and Cârloganu, C and Carniol, B and Chau, T T and Chen, J K and Chen, S J and Cheung, Y E and da Silva, W and Dauncey, P D and Densham, C and Devidze, G and Dornan, P and Drutskoy, A and Duginov, V and Eguchi, Y and Epshteyn, L B and Evtoukhovitch, P and Fayer, S and Fedotovich, G V and Finger Jr, M and Finger, M and Fujii, Y and Fukao, Y and Gabriel, J L and Gay, P and Gillies, E and Grigoriev, D N and Gritsay, K and Hai, V H and Hamada, E and Hashim, I H and Hashimoto, S and Hayashi, O and Hayashi, T and Hiasa, T and Ibrahim, Z A and Igarashi, Y and Ignatov, F V and Iio, M and Ishibashi, K and Issadykov, A and Itahashi, T and Jansen, A and Jiang, X S and Jonsson, P and Kachelhoffer, T and Kalinnikov, V and Kaneva, E and Kapusta, F and Katayama, H and Kawagoe, K and Kawashima, R and Kazak, N and Kazanin, V F and Kemularia, O and Khvedelidze, A and Koike, M and Kormoll, T and Kozlov, G A and Kozyrev, A N and Kravchenko, M and Krikler, B and Kumsiashvili, G and Kuno, Y and Kuriyama, Y and Kurochkin, Y and Kurup, A and Lagrange, B and Lai, J and Lee, M J and Li, H B and Litchfield, R P and Li, W G and Loan, T and Lomidze, D and Lomidze, I and Loveridge, P and Macharashvili, G and Makida, Y and Mao, Y J and Markin, O and Matsuda, Y and Melkadze, A and Melnik, A and Mibe, T and Mihara, S and Miyamoto, N and Miyazaki, Y and Mohamad Idris, F and Azmi, K A Mohamed Kamal and Moiseenko, A and Moritsu, M and Mori, Y and Motoishi, T and Nakai, H and Nakai, Y and Nakamoto, T and Nakamura, Y and Nakatsugawa, Y and Nakazawa, Y and Nash, J and Natori, H and Niess, V and Nioradze, M and Nishiguchi, H and Noguchi, K and Numao, T and O’Dell, J and Ogitsu, T and Ohta, S and Oishi, K and Okamoto, K and Okamura, T and Okinaka, K and Omori, C and Ota, T and Pasternak, J and Paulau, A and Picters, D and Ponariadov, V and Quémener, G and Ruban, A A and Rusinov, V and Sabirov, B and Sakamoto, H and Sarin, P and Sasaki, K and Sato, A and Sato, J and Semertzidis, Y K and Shigyo, N and Shoukavy, Dz and Slunecka, M and Stöckinger, D and Sugano, M and Tachimoto, T and Takayanagi, T and Tanaka, M and Tang, J and Tao, C V and Teixeira, A M and Tevzadze, Y and Thanh, T and Tojo, J and Tolmachev, S S and Tomasek, M and Tomizawa, M and Toriashvili, T and Trang, H and Trekov, I and Tsamalaidze, Z and Tsverava, N and Uchida, T and Uchida, Y and Ueno, K and Velicheva, E and Volkov, A and Vrba, V and Abdullah, W A T Wan and Warin-Charpentier, P and Wong, M L and Wong, T S and Wu, C and Xing, T Y and Yamaguchi, H and Yamamoto, A and Yamanaka, M and Yamane, T and Yang, Y and Yano, T and Yao, W C and Yeo, B and Yoshida, H and Yoshida, M and Yoshioka, T and Yuan, Y and Yudin, Yu V and Zdorovets, M V and Zhang, J and Zhang, Y and Zuber, K},
	volume       = 2020,
	number       = 3,
	pages        = {033C01},
	doi          = {10.1093/ptep/ptz125},
	issn         = {2050-3911},
	url          = {https://academic.oup.com/ptep/article/doi/10.1093/ptep/ptz125/5805094},
	urldate      = {2021-01-29},
	abstract     = {Abstract The Technical Design for the {COMET} Phase-I experiment is presented in this paper. {COMET} is an experiment at J-{PARC}, Japan, which will search for neutrinoless conversion of muons into electrons in the field of an aluminum nucleus (\${\textbackslash}mu\$–\$e\$ conversion, \${\textbackslash}mu{\textasciicircum}\{-\}N {\textbackslash}rightarrow e{\textasciicircum}\{-\}N\$); a lepton flavor-violating process. The experimental sensitivity goal for this process in the Phase-I experiment is \$3.1{\textbackslash}times10{\textasciicircum}\{-15\}\$, or 90\% upper limit of a branching ratio of \$7{\textbackslash}times 10{\textasciicircum}\{-15\}\$, which is a factor of 100 improvement over the existing limit. The expected number of background events is 0.032. To achieve the target sensitivity and background level, the 3.2 {kW} 8 {GeV} proton beam from J-{PARC} will be used. Two types of detectors, {CyDet} and {StrECAL}, will be used for detecting the \${\textbackslash}mu\$–\$e\$ conversion events, and for measuring the beam-related background events in view of the Phase-{II} experiment, respectively. Results from simulation on signal and background estimations are also described.},
	journaltitle = {Progress of Theoretical and Experimental Physics},
	date         = {2020-03-01},
	langid       = {english},
	file         = {The COMET Collaboration et al. - 2020 - COMET Phase-I technical design report.pdf:/home/md618/Zotero/storage/IFDUFLGP/The COMET Collaboration et al. - 2020 - COMET Phase-I technical design report.pdf:application/pdf}
}
@article{Bertl:2006up,
	title        = {{A Search for muon to electron conversion in muonic gold}},
	author       = {Bertl, Wilhelm H. and others},
	year         = 2006,
	journal      = {Eur. Phys. J. C},
	volume       = 47,
	pages        = {337--346},
	doi          = {10.1140/epjc/s2006-02582-x},
	collaboration = {SINDRUM II}
}
@inproceedings{10.5555/3295222.3295408,
	title        = {GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium},
	author       = {Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
	year         = 2017,
	booktitle    = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
	location     = {Long Beach, California, USA},
	publisher    = {Curran Associates Inc.},
	address      = {Red Hook, NY, USA},
	series       = {NIPS'17},
	pages        = {6629–6640},
	isbn         = 9781510860964,
	abstract     = {Generative Adversarial Networks (GANs) excel at creating realistic images with complex models for which maximum likelihood is infeasible. However, the convergence of GAN training has still not been proved. We propose a two time-scale update rule (TTUR) for training GANs with stochastic gradient descent on arbitrary GAN loss functions. TTUR has an individual learning rate for both the discriminator and the generator. Using the theory of stochastic approximation, we prove that the TTUR converges under mild assumptions to a stationary local Nash equilibrium. The convergence carries over to the popular Adam optimization, for which we prove that it follows the dynamics of a heavy ball with friction and thus prefers flat minima in the objective landscape. For the evaluation of the performance of GANs at image generation, we introduce the 'Fr\'{e}chet Inception Distance" (FID) which captures the similarity of generated images to real ones better than the Inception Score. In experiments, TTUR improves learning for DCGANs and Improved Wasserstein GANs (WGAN-GP) outperforming conventional GAN training on CelebA, CIFAR-10, SVHN, LSUN Bedrooms, and the One Billion Word Benchmark.},
	numpages     = 12
}
@inproceedings{7780677,
	title        = {Rethinking the Inception Architecture for Computer Vision},
	author       = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
	year         = 2016,
	booktitle    = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	volume       = {},
	number       = {},
	pages        = {2818--2826},
	doi          = {10.1109/CVPR.2016.308}
}
@article{10.1214/aoms/1177729694,
	title        = {{On Information and Sufficiency}},
	author       = {S. Kullback and R. A. Leibler},
	year         = 1951,
	journal      = {The Annals of Mathematical Statistics},
	publisher    = {Institute of Mathematical Statistics},
	volume       = 22,
	number       = 1,
	pages        = {79 -- 86},
	doi          = {10.1214/aoms/1177729694},
	url          = {https://doi.org/10.1214/aoms/1177729694}
}
@inproceedings{kilgour19_interspeech,
	title        = {{Fréchet Audio Distance: A Reference-Free Metric for Evaluating Music Enhancement Algorithms}},
	author       = {Kevin Kilgour and Mauricio Zuluaga and Dominik Roblek and Matthew Sharifi},
	year         = 2019,
	booktitle    = {Proc. Interspeech 2019},
	pages        = {2350--2354},
	doi          = {10.21437/Interspeech.2019-2219}
}
@article{Unterthiner2018TowardsAG,
	title        = {Towards Accurate Generative Models of Video: A New Metric \& Challenges},
	author       = {Thomas Unterthiner and Sjoerd van Steenkiste and Karol Kurach and Rapha{\"e}l Marinier and Marcin Michalski and Sylvain Gelly},
	year         = 2018,
	journal      = {ArXiv},
	volume       = {abs/1812.01717}
}
@article{lin_pacgan_2018,
	title        = {{PacGAN}: The power of two samples in generative adversarial networks},
	shorttitle   = {{PacGAN}},
	author       = {Lin, Zinan and Khetan, Ashish and Fanti, Giulia and Oh, Sewoong},
	url          = {http://arxiv.org/abs/1712.04086},
	urldate      = {2021-02-04},
	abstract     = {Generative adversarial networks ({GANs}) are innovative techniques for learning generative models of complex data distributions from samples. Despite remarkable recent improvements in generating realistic images, one of their major shortcomings is the fact that in practice, they tend to produce samples with little diversity, even when trained on diverse datasets. This phenomenon, known as mode collapse, has been the main focus of several recent advances in {GANs}. Yet there is little understanding of why mode collapse happens and why recently proposed approaches are able to mitigate mode collapse. We propose a principled approach to handling mode collapse, which we call packing. The main idea is to modify the discriminator to make decisions based on multiple samples from the same class, either real or artiﬁcially generated. We borrow analysis tools from binary hypothesis testing—in particular the seminal result of Blackwell [6]—to prove a fundamental connection between packing and mode collapse. We show that packing naturally penalizes generators with mode collapse, thereby favoring generator distributions with less mode collapse during the training process. Numerical experiments on benchmark datasets suggests that packing provides signiﬁcant improvements in practice as well.},
	journaltitle = {{arXiv}:1712.04086 [cs, math, stat]},
	date         = {2018-11-02},
	langid       = {english},
	eprinttype   = {arxiv},
	eprint       = {1712.04086},
	keywords     = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Information Theory},
	file         = {Lin et al. - 2018 - PacGAN The power of two samples in generative adv.pdf:/home/md618/Zotero/storage/V7R5U7ER/Lin et al. - 2018 - PacGAN The power of two samples in generative adv.pdf:application/pdf}
}
@inproceedings{45822,
	title        = {Categorical Reparameterization with Gumbel-Softmax},
	author       = {Eric Jang and Shixiang Gu and Ben Poole},
	year         = 2017,
	url          = {https://arxiv.org/abs/1611.01144}
}
% Muon g-2 FNAL
@article{PhysRevLett.126.141801,
	title        = {Measurement of the Positive Muon Anomalous Magnetic Moment to 0.46 ppm},
	author       = {Abi, B. and Albahri, T. and Al-Kilani, S. and Allspach, D. and Alonzi, L. P. and Anastasi, A. and Anisenkov, A. and Azfar, F. and Badgley, K. and Bae\ss{}ler, S. and Bailey, I. and Baranov, V. A. and Barlas-Yucel, E. and Barrett, T. and Barzi, E. and Basti, A. and Bedeschi, F. and Behnke, A. and Berz, M. and Bhattacharya, M. and Binney, H. P. and Bjorkquist, R. and Bloom, P. and Bono, J. and Bottalico, E. and Bowcock, T. and Boyden, D. and Cantatore, G. and Carey, R. M. and Carroll, J. and Casey, B. C. K. and Cauz, D. and Ceravolo, S. and Chakraborty, R. and Chang, S. P. and Chapelain, A. and Chappa, S. and Charity, S. and Chislett, R. and Choi, J. and Chu, Z. and Chupp, T. E. and Convery, M. E. and Conway, A. and Corradi, G. and Corrodi, S. and Cotrozzi, L. and Crnkovic, J. D. and Dabagov, S. and De Lurgio, P. M. and Debevec, P. T. and Di Falco, S. and Di Meo, P. and Di Sciascio, G. and Di Stefano, R. and Drendel, B. and Driutti, A. and Duginov, V. N. and Eads, M. and Eggert, N. and Epps, A. and Esquivel, J. and Farooq, M. and Fatemi, R. and Ferrari, C. and Fertl, M. and Fiedler, A. and Fienberg, A. T. and Fioretti, A. and Flay, D. and Foster, S. B. and Friedsam, H. and Frle\ifmmode \check{z}\else \v{z}\fi{}, E. and Froemming, N. S. and Fry, J. and Fu, C. and Gabbanini, C. and Galati, M. D. and Ganguly, S. and Garcia, A. and Gastler, D. E. and George, J. and Gibbons, L. K. and Gioiosa, A. and Giovanetti, K. L. and Girotti, P. and Gohn, W. and Gorringe, T. and Grange, J. and Grant, S. and Gray, F. and Haciomeroglu, S. and Hahn, D. and Halewood-Leagas, T. and Hampai, D. and Han, F. and Hazen, E. and Hempstead, J. and Henry, S. and Herrod, A. T. and Hertzog, D. W. and Hesketh, G. and Hibbert, A. and Hodge, Z. and Holzbauer, J. L. and Hong, K. W. and Hong, R. and Iacovacci, M. and Incagli, M. and Johnstone, C. and Johnstone, J. A. and Kammel, P. and Kargiantoulakis, M. and Karuza, M. and Kaspar, J. and Kawall, D. and Kelton, L. and Keshavarzi, A. and Kessler, D. and Khaw, K. S. and Khechadoorian, Z. and Khomutov, N. V. and Kiburg, B. and Kiburg, M. and Kim, O. and Kim, S. C. and Kim, Y. I. and King, B. and Kinnaird, N. and Korostelev, M. and Kourbanis, I. and Kraegeloh, E. and Krylov, V. A. and Kuchibhotla, A. and Kuchinskiy, N. A. and Labe, K. R. and LaBounty, J. and Lancaster, M. and Lee, M. J. and Lee, S. and Leo, S. and Li, B. and Li, D. and Li, L. and Logashenko, I. and Lorente Campos, A. and Luc\`a, A. and Lukicov, G. and Luo, G. and Lusiani, A. and Lyon, A. L. and MacCoy, B. and Madrak, R. and Makino, K. and Marignetti, F. and Mastroianni, S. and Maxfield, S. and McEvoy, M. and Merritt, W. and Mikhailichenko, A. A. and Miller, J. P. and Miozzi, S. and Morgan, J. P. and Morse, W. M. and Mott, J. and Motuk, E. and Nath, A. and Newton, D. and Nguyen, H. and Oberling, M. and Osofsky, R. and Ostiguy, J.-F. and Park, S. and Pauletta, G. and Piacentino, G. M. and Pilato, R. N. and Pitts, K. T. and Plaster, B. and Po\ifmmode \check{c}\else \v{c}\fi{}ani\ifmmode \acute{c}\else \'{c}\fi{}, D. and Pohlman, N. and Polly, C. C. and Popovic, M. and Price, J. and Quinn, B. and Raha, N. and Ramachandran, S. and Ramberg, E. and Rider, N. T. and Ritchie, J. L. and Roberts, B. L. and Rubin, D. L. and Santi, L. and Sathyan, D. and Schellman, H. and Schlesier, C. and Schreckenberger, A. and Semertzidis, Y. K. and Shatunov, Y. M. and Shemyakin, D. and Shenk, M. and Sim, D. and Smith, M. W. and Smith, A. and Soha, A. K. and Sorbara, M. and St\"ockinger, D. and Stapleton, J. and Still, D. and Stoughton, C. and Stratakis, D. and Strohman, C. and Stuttard, T. and Swanson, H. E. and Sweetmore, G. and Sweigart, D. A. and Syphers, M. J. and Tarazona, D. A. and Teubner, T. and Tewsley-Booth, A. E. and Thomson, K. and Tishchenko, V. and Tran, N. H. and Turner, W. and Valetov, E. and Vasilkova, D. and Venanzoni, G. and Volnykh, V. P. and Walton, T. and Warren, M. and Weisskopf, A. and Welty-Rieger, L. and Whitley, M. and Winter, P. and Wolski, A. and Wormald, M. and Wu, W. and Yoshikawa, C.},
	year         = 2021,
	month        = {Apr},
	journal      = {Phys. Rev. Lett.},
	publisher    = {American Physical Society},
	volume       = 126,
	pages        = 141801,
	doi          = {10.1103/PhysRevLett.126.141801},
	url          = {https://link.aps.org/doi/10.1103/PhysRevLett.126.141801},
	collaboration = {Muon $g\ensuremath{-}2$ Collaboration},
	issue        = 14,
	numpages     = 11
}
% Latest LHC-b lepton universality violation
@misc{lhcbcollaboration2021test,
	title        = {Test of lepton universality in beauty-quark decays},
	author       = {LHCb collaboration and R. Aaij and C. Abellán Beteta and T. Ackernley and B. Adeva and M. Adinolfi and H. Afsharnia and C. A. Aidala and S. Aiola and Z. Ajaltouni and S. Akar and J. Albrecht and F. Alessio and M. Alexander and A. Alfonso Albero and Z. Aliouche and G. Alkhazov and P. Alvarez Cartelle and S. Amato and Y. Amhis and L. An and L. Anderlini and A. Andreianov and M. Andreotti and F. Archilli and A. Artamonov and M. Artuso and K. Arzymatov and E. Aslanides and M. Atzeni and B. Audurier and S. Bachmann and M. Bachmayer and J. J. Back and P. Baladron Rodriguez and V. Balagura and W. Baldini and J. Baptista Leite and R. J. Barlow and S. Barsuk and W. Barter and M. Bartolini and F. Baryshnikov and J. M. Basels and G. Bassi and B. Batsukh and A. Battig and A. Bay and M. Becker and F. Bedeschi and I. Bediaga and A. Beiter and V. Belavin and S. Belin and V. Bellee and K. Belous and I. Belov and I. Belyaev and G. Bencivenni and E. Ben-Haim and A. Berezhnoy and R. Bernet and D. Berninghoff and H. C. Bernstein and C. Bertella and A. Bertolin and C. Betancourt and F. Betti and Ia. Bezshyiko and S. Bhasin and J. Bhom and L. Bian and M. S. Bieker and S. Bifani and P. Billoir and M. Birch and F. C. R. Bishop and A. Bitadze and A. Bizzeti and M. Bjørn and M. P. Blago and T. Blake and F. Blanc and S. Blusk and D. Bobulska and J. A. Boelhauve and O. Boente Garcia and T. Boettcher and A. Boldyrev and A. Bondar and N. Bondar and S. Borghi and M. Borisyak and M. Borsato and J. T. Borsuk and S. A. Bouchiba and T. J. V. Bowcock and A. Boyer and C. Bozzi and M. J. Bradley and S. Braun and A. Brea Rodriguez and M. Brodski and J. Brodzicka and A. Brossa Gonzalo and D. Brundu and A. Buonaura and C. Burr and A. Bursche and A. Butkevich and J. S. Butter and J. Buytaert and W. Byczynski and S. Cadeddu and H. Cai and R. Calabrese and L. Calefice and L. Calero Diaz and S. Cali and R. Calladine and M. Calvi and M. Calvo Gomez and P. Camargo Magalhaes and A. Camboni and P. Campana and A. F. Campoverde Quezada and S. Capelli and L. Capriotti and A. Carbone and G. Carboni and R. Cardinale and A. Cardini and I. Carli and P. Carniti and L. Carus and K. Carvalho Akiba and A. Casais Vidal and G. Casse and M. Cattaneo and G. Cavallero and S. Celani and J. Cerasoli and A. J. Chadwick and M. G. Chapman and M. Charles and Ph. Charpentier and G. Chatzikonstantinidis and C. A. Chavez Barajas and M. Chefdeville and C. Chen and S. Chen and A. Chernov and V. Chobanova and S. Cholak and M. Chrzaszcz and A. Chubykin and V. Chulikov and P. Ciambrone and M. F. Cicala and X. Cid Vidal and G. Ciezarek and P. E. L. Clarke and M. Clemencic and H. V. Cliff and J. Closier and J. L. Cobbledick and V. Coco and J. A. B. Coelho and J. Cogan and E. Cogneras and L. Cojocariu and P. Collins and T. Colombo and L. Congedo and A. Contu and N. Cooke and G. Coombs and G. Corti and C. M. Costa Sobral and B. Couturier and D. C. Craik and J. Crkovská and M. Cruz Torres and R. Currie and C. L. Da Silva and E. Dall'Occo and J. Dalseno and C. D'Ambrosio and A. Danilina and P. d'Argent and A. Davis and O. De Aguiar Francisco and K. De Bruyn and S. De Capua and M. De Cian and J. M. De Miranda and L. De Paula and M. De Serio and D. De Simone and P. De Simone and J. A. de Vries and C. T. Dean and D. Decamp and L. Del Buono and B. Delaney and H. -P. Dembinski and A. Dendek and V. Denysenko and D. Derkach and O. Deschamps and F. Desse and F. Dettori and B. Dey and P. Di Nezza and S. Didenko and L. Dieste Maronas and H. Dijkstra and V. Dobishuk and A. M. Donohoe and F. Dordei and A. C. dos Reis and L. Douglas and A. Dovbnya and A. G. Downes and K. Dreimanis and M. W. Dudek and L. Dufour and V. Duk and P. Durante and J. M. Durham and D. Dutta and A. Dziurda and A. Dzyuba and S. Easo and U. Egede and V. Egorychev and S. Eidelman and S. Eisenhardt and S. Ek-In and L. Eklund and S. Ely and A. Ene and E. Epple and S. Escher and J. Eschle and S. Esen and T. Evans and A. Falabella and J. Fan and Y. Fan and B. Fang and S. Farry and D. Fazzini and M. Féo and A. Fernandez Prieto and J. M. Fernandez-tenllado Arribas and A. D. Fernez and F. Ferrari and L. Ferreira Lopes and F. Ferreira Rodrigues and S. Ferreres Sole and M. Ferrillo and M. Ferro-Luzzi and S. Filippov and R. A. Fini and M. Fiorini and M. Firlej and K. M. Fischer and D. Fitzgerald and C. Fitzpatrick and T. Fiutowski and F. Fleuret and M. Fontana and F. Fontanelli and R. Forty and V. Franco Lima and M. Franco Sevilla and M. Frank and E. Franzoso and G. Frau and C. Frei and D. A. Friday and J. Fu and Q. Fuehring and W. Funk and E. Gabriel and T. Gaintseva and A. Gallas Torreira and D. Galli and S. Gambetta and Y. Gan and M. Gandelman and P. Gandini and Y. Gao and M. Garau and L. M. Garcia Martin and P. Garcia Moreno and J. García Pardiñas and B. Garcia Plana and F. A. Garcia Rosales and L. Garrido and C. Gaspar and R. E. Geertsema and D. Gerick and L. L. Gerken and E. Gersabeck and M. Gersabeck and T. Gershon and D. Gerstel and Ph. Ghez and V. Gibson and H. K. Giemza and M. Giovannetti and A. Gioventù and P. Gironella Gironell and L. Giubega and C. Giugliano and K. Gizdov and E. L. Gkougkousis and V. V. Gligorov and C. Göbel and E. Golobardes and D. Golubkov and A. Golutvin and A. Gomes and S. Gomez Fernandez and F. Goncalves Abrantes and M. Goncerz and G. Gong and P. Gorbounov and I. V. Gorelov and C. Gotti and E. Govorkova and J. P. Grabowski and T. Grammatico and L. A. Granado Cardoso and E. Graugés and E. Graverini and G. Graziani and A. Grecu and L. M. Greeven and P. Griffith and L. Grillo and S. Gromov and B. R. Gruberg Cazon and C. Gu and M. Guarise and P. A. Günther and E. Gushchin and A. Guth and Y. Guz and T. Gys and T. Hadavizadeh and G. Haefeli and C. Haen and J. Haimberger and T. Halewood-leagas and P. M. Hamilton and J. P. Hammerich and Q. Han and X. Han and T. H. Hancock and S. Hansmann-Menzemer and N. Harnew and T. Harrison and C. Hasse and M. Hatch and J. He and M. Hecker and K. Heijhoff and K. Heinicke and A. M. Hennequin and K. Hennessy and L. Henry and J. Heuel and A. Hicheur and D. Hill and M. Hilton and S. E. Hollitt and J. Hu and J. Hu and W. Hu and W. Huang and X. Huang and W. Hulsbergen and R. J. Hunter and M. Hushchyn and D. Hutchcroft and D. Hynds and P. Ibis and M. Idzik and D. Ilin and P. Ilten and A. Inglessi and A. Ishteev and K. Ivshin and R. Jacobsson and S. Jakobsen and E. Jans and B. K. Jashal and A. Jawahery and V. Jevtic and M. Jezabek and F. Jiang and M. John and D. Johnson and C. R. Jones and T. P. Jones and B. Jost and N. Jurik and S. Kandybei and Y. Kang and M. Karacson and M. Karpov and F. Keizer and M. Kenzie and T. Ketel and B. Khanji and A. Kharisova and S. Kholodenko and T. Kirn and V. S. Kirsebom and O. Kitouni and S. Klaver and K. Klimaszewski and S. Koliiev and A. Kondybayeva and A. Konoplyannikov and P. Kopciewicz and R. Kopecna and P. Koppenburg and M. Korolev and I. Kostiuk and O. Kot and S. Kotriakhova and P. Kravchenko and L. Kravchuk and R. D. Krawczyk and M. Kreps and F. Kress and S. Kretzschmar and P. Krokovny and W. Krupa and W. Krzemien and W. Kucewicz and M. Kucharczyk and V. Kudryavtsev and H. S. Kuindersma and G. J. Kunde and T. Kvaratskheliya and D. Lacarrere and G. Lafferty and A. Lai and A. Lampis and D. Lancierini and J. J. Lane and R. Lane and G. Lanfranchi and C. Langenbruch and J. Langer and O. Lantwin and T. Latham and F. Lazzari and R. Le Gac and S. H. Lee and R. Lefèvre and A. Leflat and S. Legotin and O. Leroy and T. Lesiak and B. Leverington and H. Li and L. Li and P. Li and S. Li and Y. Li and Y. Li and Z. Li and X. Liang and T. Lin and R. Lindner and V. Lisovskyi and R. Litvinov and G. Liu and H. Liu and S. Liu and X. Liu and A. Loi and J. Lomba Castro and I. Longstaff and J. H. Lopes and G. H. Lovell and Y. Lu and D. Lucchesi and S. Luchuk and M. Lucio Martinez and V. Lukashenko and Y. Luo and A. Lupato and E. Luppi and O. Lupton and A. Lusiani and X. Lyu and L. Ma and R. Ma and S. Maccolini and F. Machefert and F. Maciuc and V. Macko and P. Mackowiak and S. Maddrell-Mander and O. Madejczyk and L. R. Madhan Mohan and O. Maev and A. Maevskiy and D. Maisuzenko and M. W. Majewski and J. J. Malczewski and S. Malde and B. Malecki and A. Malinin and T. Maltsev and H. Malygina and G. Manca and G. Mancinelli and D. Manuzzi and D. Marangotto and J. Maratas and J. F. Marchand and U. Marconi and S. Mariani and C. Marin Benito and M. Marinangeli and J. Marks and A. M. Marshall and P. J. Marshall and G. Martellotti and L. Martinazzoli and M. Martinelli and D. Martinez Santos and F. Martinez Vidal and A. Massafferri and M. Materok and R. Matev and A. Mathad and Z. Mathe and V. Matiunin and C. Matteuzzi and K. R. Mattioli and A. Mauri and E. Maurice and J. Mauricio and M. Mazurek and M. McCann and L. Mcconnell and T. H. Mcgrath and A. McNab and R. McNulty and J. V. Mead and B. Meadows and C. Meaux and G. Meier and N. Meinert and D. Melnychuk and S. Meloni and M. Merk and A. Merli and L. Meyer Garcia and M. Mikhasenko and D. A. Milanes and E. Millard and M. Milovanovic and M. -N. Minard and A. Minotti and L. Minzoni and S. E. Mitchell and B. Mitreska and D. S. Mitzel and A. Mödden and R. A. Mohammed and R. D. Moise and T. Mombächer and I. A. Monroy and S. Monteil and M. Morandin and G. Morello and M. J. Morello and J. Moron and A. B. Morris and A. G. Morris and R. Mountain and H. Mu and F. Muheim and M. Mulder and D. Müller and K. Müller and C. H. Murphy and D. Murray and P. Muzzetto and P. Naik and T. Nakada and R. Nandakumar and T. Nanut and I. Nasteva and M. Needham and I. Neri and N. Neri and S. Neubert and N. Neufeld and R. Newcombe and T. D. Nguyen and C. Nguyen-Mau and E. M. Niel and S. Nieswand and N. Nikitin and N. S. Nolte and C. Nunez and A. Oblakowska-Mucha and V. Obraztsov and D. P. O'Hanlon and R. Oldeman and M. E. Olivares and C. J. G. Onderwater and A. Ossowska and J. M. Otalora Goicochea and T. Ovsiannikova and P. Owen and A. Oyanguren and B. Pagare and P. R. Pais and T. Pajero and A. Palano and M. Palutan and Y. Pan and G. Panshin and A. Papanestis and M. Pappagallo and L. L. Pappalardo and C. Pappenheimer and W. Parker and C. Parkes and C. J. Parkinson and B. Passalacqua and G. Passaleva and A. Pastore and M. Patel and C. Patrignani and C. J. Pawley and A. Pearce and A. Pellegrino and M. Pepe Altarelli and S. Perazzini and D. Pereima and P. Perret and M. Petric and K. Petridis and A. Petrolini and A. Petrov and S. Petrucci and M. Petruzzo and T. T. H. Pham and A. Philippov and L. Pica and M. Piccini and B. Pietrzyk and G. Pietrzyk and M. Pili and D. Pinci and F. Pisani and Resmi P. K and V. Placinta and J. Plews and M. Plo Casasus and F. Polci and M. Poli Lener and M. Poliakova and A. Poluektov and N. Polukhina and I. Polyakov and E. Polycarpo and G. J. Pomery and S. Ponce and D. Popov and S. Popov and S. Poslavskii and K. Prasanth and L. Promberger and C. Prouve and V. Pugatch and H. Pullen and G. Punzi and W. Qian and J. Qin and R. Quagliani and B. Quintana and N. V. Raab and R. I. Rabadan Trejo and B. Rachwal and J. H. Rademacker and M. Rama and M. Ramos Pernas and M. S. Rangel and F. Ratnikov and G. Raven and M. Reboud and F. Redi and F. Reiss and C. Remon Alepuz and Z. Ren and V. Renaudin and R. Ribatti and S. Ricciardi and K. Rinnert and P. Robbe and G. Robertson and A. B. Rodrigues and E. Rodrigues and J. A. Rodriguez Lopez and A. Rollings and P. Roloff and V. Romanovskiy and M. Romero Lamas and A. Romero Vidal and J. D. Roth and M. Rotondo and M. S. Rudolph and T. Ruf and J. Ruiz Vidal and A. Ryzhikov and J. Ryzka and J. J. Saborido Silva and N. Sagidova and N. Sahoo and B. Saitta and M. Salomoni and D. Sanchez Gonzalo and C. Sanchez Gras and R. Santacesaria and C. Santamarina Rios and M. Santimaria and E. Santovetti and D. Saranin and G. Sarpis and M. Sarpis and A. Sarti and C. Satriano and A. Satta and M. Saur and D. Savrina and H. Sazak and L. G. Scantlebury Smead and S. Schael and M. Schellenberg and M. Schiller and H. Schindler and M. Schmelling and B. Schmidt and O. Schneider and A. Schopper and M. Schubiger and S. Schulte and M. H. Schune and R. Schwemmer and B. Sciascia and S. Sellam and A. Semennikov and M. Senghi Soares and A. Sergi and N. Serra and L. Sestini and A. Seuthe and P. Seyfert and Y. Shang and D. M. Shangase and M. Shapkin and I. Shchemerov and L. Shchutska and T. Shears and L. Shekhtman and Z. Shen and V. Shevchenko and E. B. Shields and E. Shmanin and J. D. Shupperd and B. G. Siddi and R. Silva Coutinho and G. Simi and S. Simone and N. Skidmore and T. Skwarnicki and M. W. Slater and I. Slazyk and J. C. Smallwood and J. G. Smeaton and A. Smetkina and E. Smith and M. Smith and A. Snoch and M. Soares and L. Soares Lavra and M. D. Sokoloff and F. J. P. Soler and A. Solovev and I. Solovyev and F. L. Souza De Almeida and B. Souza De Paula and B. Spaan and E. Spadaro Norella and P. Spradlin and F. Stagni and M. Stahl and S. Stahl and P. Stefko and O. Steinkamp and O. Stenyakin and H. Stevens and S. Stone and M. E. Stramaglia and M. Straticiuc and D. Strekalina and F. Suljik and J. Sun and L. Sun and Y. Sun and P. Svihra and P. N. Swallow and K. Swientek and A. Szabelski and T. Szumlak and M. Szymanski and S. Taneja and F. Teubert and E. Thomas and K. A. Thomson and V. Tisserand and S. T'Jampens and M. Tobin and L. Tomassetti and D. Torres Machado and D. Y. Tou and M. T. Tran and E. Trifonova and C. Trippl and G. Tuci and A. Tully and N. Tuning and A. Ukleja and D. J. Unverzagt and E. Ursov and A. Usachov and A. Ustyuzhanin and U. Uwer and A. Vagner and V. Vagnoni and A. Valassi and G. Valenti and N. Valls Canudas and M. van Beuzekom and M. Van Dijk and E. van Herwijnen and C. B. Van Hulse and M. van Veghel and R. Vazquez Gomez and P. Vazquez Regueiro and C. Vázquez Sierra and S. Vecchi and J. J. Velthuis and M. Veltri and A. Venkateswaran and M. Veronesi and M. Vesterinen and D. Vieira and M. Vieites Diaz and H. Viemann and X. Vilasis-Cardona and E. Vilella Figueras and P. Vincent and D. Vom Bruch and A. Vorobyev and V. Vorobyev and N. Voropaev and R. Waldi and J. Walsh and C. Wang and J. Wang and J. Wang and J. Wang and J. Wang and M. Wang and R. Wang and Y. Wang and Z. Wang and Z. Wang and H. M. Wark and N. K. Watson and S. G. Weber and D. Websdale and C. Weisser and B. D. C. Westhenry and D. J. White and M. Whitehead and D. Wiedner and G. Wilkinson and M. Wilkinson and I. Williams and M. Williams and M. R. J. Williams and F. F. Wilson and W. Wislicki and M. Witek and L. Witola and G. Wormser and S. A. Wotton and H. Wu and K. Wyllie and Z. Xiang and D. Xiao and Y. Xie and A. Xu and J. Xu and L. Xu and M. Xu and Q. Xu and Z. Xu and Z. Xu and D. Yang and S. Yang and Y. Yang and Z. Yang and Z. Yang and Y. Yao and L. E. Yeomans and H. Yin and J. Yu and X. Yuan and O. Yushchenko and E. Zaffaroni and M. Zavertyaev and M. Zdybal and O. Zenaiev and M. Zeng and D. Zhang and L. Zhang and S. Zhang and Y. Zhang and Y. Zhang and A. Zhelezov and Y. Zheng and X. Zhou and Y. Zhou and X. Zhu and Z. Zhu and V. Zhukov and J. B. Zonneveld and Q. Zou and S. Zucchelli and D. Zuliani and G. Zunica},
	year         = 2021,
	eprint       = {2103.11769},
	archiveprefix = {arXiv},
	primaryclass = {hep-ex}
}
@article{BERNSTEIN201327,
	title        = {Charged lepton flavor violation: An experimenter’s guide},
	author       = {R.H. Bernstein and Peter S. Cooper},
	year         = 2013,
	journal      = {Physics Reports},
	volume       = 532,
	number       = 2,
	pages        = {27--64},
	doi          = {https://doi.org/10.1016/j.physrep.2013.07.002},
	issn         = {0370-1573},
	url          = {https://www.sciencedirect.com/science/article/pii/S0370157313002688},
	note         = {Charged Lepton Flavor Violation: An Experimenter's Guide},
	keywords     = {Electron, Muon, Tau, Flavor},
	abstract     = {Charged lepton flavor violation (CLFV) is a clear signal of new physics; it directly addresses the physics of flavor and of generations. The search for CLFV has continued from the early 1940s, when the muon was identified as a separate particle, until today. Certainly in the LHC era the motivations for continued searches are clear and have been covered in many reviews. This review is focused on the experimental history with a view toward how these searches might progress. We examine the status of searches for charged lepton flavor violation in the muon, tau, and other channels, and then examine the prospects for new efforts over the next decade. Finally, we examine what paths might be taken after the conclusion of upcoming experiments and what facilities might be required.}
}
@article{Baldini2018,
	title        = {The design of the MEG II experiment},
	author       = {Baldini, A. M. and Baracchini, E. and Bemporad, C. and Berg, F. and Biasotti, M. and Boca, G. and Cattaneo, P. W. and Cavoto, G. and Cei, F. and Chiappini, M. and Chiarello, G. and Chiri, C. and Cocciolo, G. and Corvaglia, A. and de Bari, A. and De Gerone, M. and D'Onofrio, A. and Francesconi, M. and Fujii, Y. and Galli, L. and Gatti, F. and Grancagnolo, F. and Grassi, M. and Grigoriev, D. N. and Hildebrandt, M. and Hodge, Z. and Ieki, K. and Ignatov, F. and Iwai, R. and Iwamoto, T. and Kaneko, D. and Kasami, K. and Kettle, P.-R. and Khazin, B. I. and Khomutov, N. and Korenchenko, A. and Kravchuk, N. and Libeiro, T. and Maki, M. and Matsuzawa, N. and Mihara, S. and Milgie, M. and Molzon, W. and Mori, Toshinori and Morsani, F. and Mtchedilishvili, A. and Nakao, M. and Nakaura, S. and Nicol{\`o}, D. and Nishiguchi, H. and Nishimura, M. and Ogawa, S. and Ootani, W. and Panareo, M. and Papa, A. and Pepino, A. and Piredda, G. and Popov, A. and Raffaelli, F. and Renga, F. and Ripiccini, E. and Ritt, S. and Rossella, M. and Rutar, G. and Sawada, R. and Signorelli, G. and Simonetta, M. and Tassielli, G. F. and Uchiyama, Y. and Usami, M. and Venturini, M. and Voena, C. and Yoshida, K. and Yudin, Yu. V. and Zhang, Y.},
	year         = 2018,
	month        = {May},
	day          = 16,
	journal      = {The European Physical Journal C},
	volume       = 78,
	number       = 5,
	pages        = 380,
	doi          = {10.1140/epjc/s10052-018-5845-6},
	issn         = {1434-6052},
	url          = {https://doi.org/10.1140/epjc/s10052-018-5845-6},
	abstract     = {The MEG experiment, designed to search for the {\$}{\$}{\{}{\backslash}mu ^+ {\backslash}rightarrow {\backslash}hbox {\{}e{\}}^+ {\backslash}gamma {\}}{\$}{\$}decay, completed data-taking in 2013 reaching a sensitivity level of {\$}{\$}{\{}5.3{\backslash}times 10^{\{}-13{\}}{\}}{\$}{\$}for the branching ratio. In order to increase the sensitivity reach of the experiment by an order of magnitude to the level of {\$}{\$}6{\backslash}times 10^{\{}-14{\}}{\$}{\$}, a total upgrade, involving substantial changes to the experiment, has been undertaken, known as MEG II. We present both the motivation for the upgrade and a detailed overview of the design of the experiment and of the expected detector performance.}
}
@misc{bartoszek2015mu2e,
	title        = {Mu2e Technical Design Report},
	author       = {L. Bartoszek and E. Barnes and J. P. Miller and J. Mott and A. Palladino and J. Quirk and B. L. Roberts and J. Crnkovic and V. Polychronakos and V. Tishchenko and P. Yamin and C. -h. Cheng and B. Echenard and K. Flood and D. G. Hitlin and J. H. Kim and T. S. Miyashita and F. C. Porter and M. Röhrken and J. Trevor and R. -Y. Zhu and E. Heckmaier and T. I. Kang and G. Lim and W. Molzon and Z. You and A. M. Artikov and J. A. Budagov and Yu. I. Davydov and V. V. Glagolev and A. V. Simonenko and Z. U. Usubov and S. H. Oh and C. Wang and G. Ambrosio and N. Andreev and D. Arnold and M. Ball and R. H. Bernstein and A. Bianchi and K. Biery and R. Bossert and M. Bowden and J. Brandt and G. Brown and H. Brown and M. Buehler and M. Campbell and S. Cheban and M. Chen and J. Coghill and R. Coleman and C. Crowley and A. Deshpande and G. Deuerling and J. Dey and N. Dhanaraj and M. Dinnon and S. Dixon and B. Drendel and N. Eddy and R. Evans and D. Evbota and J. Fagan and S. Feher and B. Fellenz and H. Friedsam and G. Gallo and A. Gaponenko and M. Gardner and S. Gaugel and K. Genser and G. Ginther and H. Glass and D. Glenzinski and D. Hahn and S. Hansen and B. Hartsell and S. Hays and J. A. Hocker and E. Huedem and D. Huffman and A. Ibrahim and C. Johnstone and V. Kashikhin and V. V. Kashikhin and P. Kasper and T. Kiper and D. Knapp and K. Knoepfel and L. Kokoska and M. Kozlovsky and G. Krafczyk and M. Kramp and S. Krave and K. Krempetz and R. K. Kutschke and R. Kwarciany and T. Lackowski and M. J. Lamm and M. Larwill and F. Leavell and D. Leeb and A. Leveling and D. Lincoln and V. Logashenko and V. Lombardo and M. L. Lopes and A. Makulski and A. Martinez and D. McArthur and F. McConologue and L. Michelotti and N. Mokhov and J. Morgan and A. Mukherjee and P. Murat and V. Nagaslaev and D. V. Neuffer and T. Nicol and J. Niehoff and J. Nogiec and M. Olson and D. Orris and R. Ostojic and T. Page and C. Park and T. Peterson and R. Pilipenko and A. Pla-Dalmau and V. Poloubotko and M. Popovic and E. Prebys and P. Prieto and V. Pronskikh and D. Pushka and R. Rabehl and R. E. Ray and R. Rechenmacher and R. Rivera and W. Robotham and P. Rubinov and V. L. Rusu and V. Scarpine and W. Schappert and D. Schoo and A. Stefanik and D. Still and Z. Tang and N. Tanovic and M. Tartaglia and G. Tassotto and D. Tinsley and R. S. Tschirhart and G. Vogel and R. Wagner and R. Wands and M. Wang and S. Werkema and H. B. White Jr. au2 and J. Whitmore and R. Wielgos and R. Woods and C. Worel and R. Zifko and P. Ciambrone and F. Colao and M. Cordelli and G. Corradi and E. Dane and S. Giovannella and F. Happacher and A. Luca and S. Miscetti and B. Ponzio and G. Pileggi and A. Saputi and I. Sarra and R. S. Soleti and V. Stomaci and M. Martini and P. Fabbricatore and S. Farinon and R. Musenich and D. Alexander and A. Daniel and A. Empl and E. V. Hungerford and K. Lau and G. D. Gollin and C. Huang and D. Roderick and B. Trundy and D. Na. Brown and D. Ding and Yu. G. Kolomensky and M. J. Lee and M. Cascella and F. Grancagnolo and F. Ignatov and A. Innocente and A. L'Erario and A. Miccoli and A. Maffezzoli and P. Mazzotta and G. Onorato and G. M. Piacentino and S. Rella and F. Rossetti and M. Spedicato and G. Tassielli and A. Taurino and G. Zavarise and R. Hooper and D. No. Brown and R. Djilkibaev and V. Matushko and C. Ankenbrandt and S. Boi and A. Dychkant and D. Hedin and Z. Hodge and V. Khalatian and R. Majewski and L. Martin and U. Okafor and N. Pohlman and R. S. Riddel and A. Shellito and A. L. de Gouvea and F. Cervelli and R. Carosi and S. Di Falco and S. Donati and T. Lomtadze and G. Pezzullo and L. Ristori and F. Spinella and M. Jones and M. D. Corcoran and J. Orduna and D. Rivera and R. Bennett and O. Caretta and T. Davenne and C. Densham and P. Loveridge and J. Odell and R. Bomgardner and E. C. Dukes and R. Ehrlich and M. Frank and S. Goadhouse and R. Group and E. Ho and H. Ma and Y. Oksuzian and J. Purvis and Y. Wu and D. W. Hertzog and P. Kammel and K. R. Lynch and J. L. Popp},
	year         = 2015,
	eprint       = {1501.05241},
	archiveprefix = {arXiv},
	primaryclass = {physics.ins-det}
}
@article{ARNDT2021165679,
	title        = {Technical design of the phase I Mu3e experiment},
	author       = {K. Arndt and H. Augustin and P. Baesso and N. Berger and F. Berg and C. Betancourt and D. Bortoletto and A. Bravar and K. Briggl and D. {vom Bruch} and A. Buonaura and F. Cadoux and C. Chavez Barajas and H. Chen and K. Clark and P. Cooke and S. Corrodi and A. Damyanova and Y. Demets and S. Dittmeier and P. Eckert and F. Ehrler and D. Fahrni and S. Gagneur and L. Gerritzen and J. Goldstein and D. Gottschalk and C. Grab and R. Gredig and A. Groves and J. Hammerich and U. Hartenstein and U. Hartmann and H. Hayward and A. Herkert and G. Hesketh and S. Hetzel and M. Hildebrandt and Z. Hodge and A. Hofer and Q.H. Huang and S. Hughes and L. Huth and D.M. Immig and T. Jones and M. Jones and H.-C. Kästli and M. Köppel and P.-R. Kettle and M. Kiehn and S. Kilani and H. Klingenmeyer and A. Knecht and A. Knight and B. Kotlinski and A. Kozlinskiy and R. Leys and G. Lockwood and A. Loreti and D. {La Marra} and M. Müller and B. Meier and F. Meier Aeschbacher and A. Meneses and K. Metodiev and A. Mtchedlishvili and S. Muley and Y. Munwes and L.O.S. Noehte and P. Owen and A. Papa and I. Paraskevas and I. Perić and A.-K. Perrevoort and R. Plackett and M. Pohl and S. Ritt and P. Robmann and N. Rompotis and T. Rudzki and G. Rutar and A. Schöning and R. Schimassek and H.-C. Schultz-Coulon and N. Serra and W. Shen and I. Shipsey and S. Shrestha and O. Steinkamp and A. Stoykov and U. Straumann and S. Streuli and K. Stumpf and N. Tata and J. Velthuis and L. Vigani and E. Vilella-Figueras and J. Vossebeld and R. Wallny and A. Wasili and F. Wauters and A. Weber and D. Wiedner and B. Windelband and T. Zhong},
	year         = 2021,
	journal      = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
	volume       = 1014,
	pages        = 165679,
	doi          = {https://doi.org/10.1016/j.nima.2021.165679},
	issn         = {0168-9002},
	url          = {https://www.sciencedirect.com/science/article/pii/S0168900221006641},
	keywords     = {Lepton flavour violation, Muon decays, Monolithic pixel detector, Scintillating fibres, Scintillating tiles},
	abstract     = {The Mu3e experiment aims to find or exclude the lepton flavour violating decay μ→eee at branching fractions above 10−16. A first phase of the experiment using an existing beamline at the Paul Scherrer Institute (PSI) is designed to reach a single event sensitivity of 2⋅10−15. We present an overview of all aspects of the technical design and expected performance of the phase I Mu3e detector. The high rate of up to 108 muon decays per second and the low momenta of the decay electrons and positrons pose a unique set of challenges, which we tackle using an ultra thin tracking detector based on high-voltage monolithic active pixel sensors combined with scintillating fibres and tiles for precise timing measurements.}
}
@article{BRUN199781,
	title        = {ROOT — An object oriented data analysis framework},
	author       = {Rene Brun and Fons Rademakers},
	year         = 1997,
	journal      = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
	volume       = 389,
	number       = 1,
	pages        = {81--86},
	doi          = {https://doi.org/10.1016/S0168-9002(97)00048-X},
	issn         = {0168-9002},
	url          = {http://www.sciencedirect.com/science/article/pii/S016890029700048X},
	note         = {New Computing Techniques in Physics Research V},
	abstract     = {The ROOT system in an Object Oriented framework for large scale data analysis. ROOT written in C++, contains, among others, an efficient hierarchical OO database, a C++ interpreter, advanced statistical analysis (multi-dimensional histogramming, fitting, minimization, cluster finding algorithms) and visualization tools. The user interacts with ROOT via a graphical user interface, the command line or batch scripts. The command and scripting language is C++ (using the interpreter) and large scripts can be compiled and dynamically linked in. The OO database design has been optimized for parallel access (reading as well as writing) by multiple processes.}
}
@article{AGOSTINELLI2003250,
	title        = {Geant4—a simulation toolkit},
	author       = {S. Agostinelli and J. Allison and K. Amako and J. Apostolakis and H. Araujo and P. Arce and M. Asai and D. Axen and S. Banerjee and G. Barrand and F. Behner and L. Bellagamba and J. Boudreau and L. Broglia and A. Brunengo and H. Burkhardt and S. Chauvie and J. Chuma and R. Chytracek and G. Cooperman and G. Cosmo and P. Degtyarenko and A. Dell'Acqua and G. Depaola and D. Dietrich and R. Enami and A. Feliciello and C. Ferguson and H. Fesefeldt and G. Folger and F. Foppiano and A. Forti and S. Garelli and S. Giani and R. Giannitrapani and D. Gibin and J.J. [Gómez Cadenas] and I. González and G. [Gracia Abril] and G. Greeniaus and W. Greiner and V. Grichine and A. Grossheim and S. Guatelli and P. Gumplinger and R. Hamatsu and K. Hashimoto and H. Hasui and A. Heikkinen and A. Howard and V. Ivanchenko and A. Johnson and F.W. Jones and J. Kallenbach and N. Kanaya and M. Kawabata and Y. Kawabata and M. Kawaguti and S. Kelner and P. Kent and A. Kimura and T. Kodama and R. Kokoulin and M. Kossov and H. Kurashige and E. Lamanna and T. Lampén and V. Lara and V. Lefebure and F. Lei and M. Liendl and W. Lockman and F. Longo and S. Magni and M. Maire and E. Medernach and K. Minamimoto and P. [Mora de Freitas] and Y. Morita and K. Murakami and M. Nagamatu and R. Nartallo and P. Nieminen and T. Nishimura and K. Ohtsubo and M. Okamura and S. O'Neale and Y. Oohata and K. Paech and J. Perl and A. Pfeiffer and M.G. Pia and F. Ranjard and A. Rybin and S. Sadilov and E. [Di Salvo] and G. Santin and T. Sasaki and N. Savvas and Y. Sawada and S. Scherer and S. Sei and V. Sirotenko and D. Smith and N. Starkov and H. Stoecker and J. Sulkimo and M. Takahata and S. Tanaka and E. Tcherniaev and E. [Safai Tehrani] and M. Tropeano and P. Truscott and H. Uno and L. Urban and P. Urban and M. Verderi and A. Walkden and W. Wander and H. Weber and J.P. Wellisch and T. Wenaus and D.C. Williams and D. Wright and T. Yamada and H. Yoshida and D. Zschiesche},
	year         = 2003,
	journal      = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
	volume       = 506,
	number       = 3,
	pages        = {250--303},
	doi          = {https://doi.org/10.1016/S0168-9002(03)01368-8},
	issn         = {0168-9002},
	url          = {http://www.sciencedirect.com/science/article/pii/S0168900203013688},
	keywords     = {Simulation, Particle interactions, Geometrical modelling, Software engineering, Object-oriented technology, Distributed software development},
	abstract     = {Geant4 is a toolkit for simulating the passage of particles through matter. It includes a complete range of functionality including tracking, geometry, physics models and hits. The physics processes offered cover a comprehensive range, including electromagnetic, hadronic and optical processes, a large set of long-lived particles, materials and elements, over a wide energy range starting, in some cases, from 250eV and extending in others to the TeV energy range. It has been designed and constructed to expose the physics models utilised, to handle complex geometries, and to enable its easy adaptation for optimal use in different sets of applications. The toolkit is the result of a worldwide collaboration of physicists and software engineers. It has been created exploiting software engineering and object-oriented technology and implemented in the C++ programming language. It has been used in applications in particle physics, nuclear physics, accelerator design, space engineering and medical physics.}
}
@article{WRIGHT2015175,
	title        = {The Geant4 Bertini Cascade},
	author       = {D.H. Wright and M.H. Kelsey},
	year         = 2015,
	journal      = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
	volume       = 804,
	pages        = {175--188},
	doi          = {https://doi.org/10.1016/j.nima.2015.09.058},
	issn         = {0168-9002},
	url          = {https://www.sciencedirect.com/science/article/pii/S0168900215011134},
	keywords     = {Hadronic physics models, Simulation, Geant4},
	abstract     = {One of the medium energy hadron–nucleus interaction models in the Geant4 simulation toolkit is based partly on the Bertini intranuclear cascade model. Since its initial appearance in the toolkit, this model has been largely re-written in order to extend its physics capabilities and to reduce its memory footprint. Physics improvements include extensions in applicable energy range and incident particle types, and improved hadron–nucleon cross-sections and angular distributions. Interfaces have also been developed which allow the model to be coupled with other Geant4 models at lower and higher energies. The inevitable speed reductions due to enhanced physics have been mitigated by memory and CPU efficiency improvements. Details of these improvements, along with selected comparisons of the model to data, are discussed.}
}
@article{czarnecki,
	title        = {Muon decay in orbit: Spectrum of high-energy electrons},
	author       = {Czarnecki, Andrzej and Garcia i Tormo, Xavier and Marciano, William J.},
	year         = 2011,
	month        = {Jul},
	journal      = {Phys. Rev. D},
	publisher    = {American Physical Society},
	volume       = 84,
	pages        = {013006},
	doi          = {10.1103/PhysRevD.84.013006},
	url          = {https://link.aps.org/doi/10.1103/PhysRevD.84.013006},
	issue        = 1,
	numpages     = 8
}
@article{litchfield2015status,
	title        = {Status of the AlCap experiment},
	author       = {R. Phillip Litchfield},
	year         = 2015,
	journal      = {Proceedings of "16th International Workshop on Neutrino Factories and Future Neutrino Beam Facilities"},
	doi          = {https://doi.org/10.22323/1.226.0095},
	note         = {PoS(NUFACT2014)095}
}
@misc{arjovsky2017wasserstein,
	title        = {Wasserstein GAN},
	author       = {Martin Arjovsky and Soumith Chintala and Léon Bottou},
	year         = 2017,
	eprint       = {1701.07875},
	archiveprefix = {arXiv},
	primaryclass = {stat.ML}
}
@inproceedings{Carey1974DecayT,
	title        = {Decay TURTLE (Trace Unlimited Rays Through Lumped Elements): A Computer Program for Simulating Charged Particle Beam Transport Systems, Including Decay Calculations},
	author       = {David C. Carey and F. Christoph Iselin and Karl Leslie Brown},
	year         = 1974
}
@inproceedings{Maas13rectifiernonlinearities,
	title        = {Rectifier nonlinearities improve neural network acoustic models},
	author       = {Andrew L. Maas and Awni Y. Hannun and Andrew Y. Ng},
	year         = 2013,
	booktitle    = {in ICML Workshop on Deep Learning for Audio, Speech and Language Processing}
}
@article{FLUKA,
	title        = {{FLUKA: A multi-particle transport code (Program version 2005)}},
	author       = {Ferrari, Alfredo and Sala, Paola R. and Fasso, Alberto and Ranft, Johannes},
	year         = 2005,
	month        = 10,
	doi          = {10.2172/877507},
	reportnumber = {CERN-2005-010, SLAC-R-773, INFN-TC-05-11, CERN-2005-10}
}
@article{PHITS,
	title        = {Features of Particle and Heavy Ion Transport code System (PHITS) version 3.02},
	author       = {Tatsuhiko Sato and Yosuke Iwamoto and Shintaro Hashimoto and Tatsuhiko Ogawa and Takuya Furuta and Shin-ichiro Abe and Takeshi Kai and Pi-En Tsai and Norihiro Matsuda and Hiroshi Iwase and Nobuhiro Shigyo and Lembit Sihver and Koji Niita},
	year         = 2018,
	journal      = {Journal of Nuclear Science and Technology},
	publisher    = {Taylor & Francis},
	volume       = 55,
	number       = 6,
	pages        = {684--690},
	doi          = {10.1080/00223131.2017.1419890},
	url          = {https://doi.org/10.1080/00223131.2017.1419890},
	eprint       = {https://doi.org/10.1080/00223131.2017.1419890}
}
@misc{MARS15,
	title        = {MARS15, Version 00},
	author       = {Mokhov, Nikolai},
	year         = 2016,
	month        = 7,
	doi          = {},
	url          = {https://www.osti.gov/biblio/1282121},
	abstractnote = {MARS is a Monte Carlo code for inclusive and exclusive simulation of three-dimensional hadronic and electromagnetic cascades, muon, heavy-ion and low-energy neutron transport in accelerator, detector, spacecraft and shielding components in the energy range from a fraction of an electronvolt up to 100 TeV. Recent developments in the MARS15 physical models of hadron, heavy-ion and lepton interactions with nuclei and atoms include a new nuclear cross section library, a model for soft pion production, the cascade-exciton model, the quark gluon string models, deuteron-nucleus and neutrino-nucleus interaction models, detailed description of negative hadron and muon absorption and a unified treatment of muon, charged hadron and heavy-ion electromagnetic interactions with matter. New algorithms are implemented into the code and thoroughly benchmarked against experimental data. The code capabilities to simulate cascades and generate a variety of results in complex media have been also enhanced. Other changes in the current version concern the improved photo- and electro-production of hadrons and muons, improved algorithms for the 3-body decays, particle tracking in magnetic fields, synchrotron radiation by electrons and muons, significantly extended histograming capabilities and material description, and improved computational performance. In addition to direct energy deposition calculations, a new set of fluence-to-dose conversion factors for all particles including neutrino are built into the code. The code includes new modules for calculation of Displacement-per-Atom and nuclide inventory. The powerful ROOT geometry and visualization model implemented in MARS15 provides a large set of geometrical elements with a possibility of producing composite shapes and assemblies and their 3D visualization along with a possible import/export of geometry descriptions created by other codes (via the GDML format) and CAD systems (via the STEP format). The built-in MARS-MAD Beamline Builder (MMBLB) was redesigned for use with the ROOT geometry package that allows a very efficient and highly-accurate description, modeling and visualization of beam loss induced effects in arbitrary beamlines and accelerator lattices. The MARS15 code includes links to the MCNP-family codes for neutron and photon production and transport below 20 MeV, to the ANSYS code for thermal and stress analyses and to the STRUCT code for multi-turn particle tracking in large synchrotrons and collider rings.}
}
@article{sklearn,
	title        = {Scikit-learn: Machine learning in Python},
	author       = {Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and others},
	year         = 2011,
	journal      = {Journal of machine learning research},
	volume       = 12,
	number       = {Oct},
	pages        = {2825--2830}
}
@article{kansal2020graph,
	title        = {Graph Generative Adversarial Networks for Sparse Data Generation in High Energy Physics},
	author       = {Kansal, Raghav and Duarte, Javier and Orzari, Breno and Tomei, Thiago and Pierini, Maurizio and Touranakou, Mary and Vlimant, Jean-Roch and Gunopulos, Dimitrios},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2012.00173}
}
@article{LATTES1947,
	author={LATTES, C. M. G.
	and MUIRHEAD, H.
	and OCCHIALINI, G. P. S.
	and POWELL, C. F.},
	title={PROCESSES INVOLVING CHARGED MESONS},
	journal={Nature},
	year={1947},
	month={May},
	day={01},
	volume={159},
	number={4047},
	pages={694-697},
	abstract={In recent investigations with the photographic method1,2, it has been shown that slow charged particles of small mass, present as a component of the cosmic radiation at high altitudes, can enter nuclei and produce disintegrations with the emission of heavy particles. It is convenient to apply the term `meson' to any particle with a mass intermediate between that of a proton and an electron. In continuing our experiments we have found evidence of mesons which, at the end of their range, produce secondary mesons. We have also observed transmutations in which slow mesons are ejected from disintegrating nuclei. Several features of these processes remain to be elucidated, but we present the following account of the experiments because the results appear to bear closely on the important problem of developing a satisfactory meson theory of nuclear forces.},
	issn={1476-4687},
	doi={10.1038/159694a0},
	url={https://doi.org/10.1038/159694a0}
}
@article{PhysRev.51.884,
	title = {Note on the Nature of Cosmic-Ray Particles},
	author = {Neddermeyer, Seth H. and Anderson, Carl D.},
	journal = {Phys. Rev.},
	volume = {51},
	issue = {10},
	pages = {884--886},
	numpages = {0},
	year = {1937},
	month = {May},
	publisher = {American Physical Society},
	doi = {10.1103/PhysRev.51.884},
	url = {https://link.aps.org/doi/10.1103/PhysRev.51.884}
}
@article{10.1143/PTPS.1.1,
    author = {Yukawa, Hideki},
    title = "{On the Interaction of Elementary Particles. I}",
    journal = {Progress of Theoretical Physics Supplement},
    volume = {1},
    pages = {1-10},
    year = {1955},
    month = {01},
    issn = {0375-9687},
    doi = {10.1143/PTPS.1.1},
    url = {https://doi.org/10.1143/PTPS.1.1},
    eprint = {https://academic.oup.com/ptps/article-pdf/doi/10.1143/PTPS.1.1/5310694/1-1.pdf},
}
@article{PhysRev.52.1198,
  title = {On the Nature of Cosmic-Ray Particles},
  author = {Nishina, Y. and Takeuchi, M. and Ichimiya, T.},
  journal = {Phys. Rev.},
  volume = {52},
  issue = {11},
  pages = {1198--1199},
  numpages = {0},
  year = {1937},
  month = {Dec},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRev.52.1198},
  url = {https://link.aps.org/doi/10.1103/PhysRev.52.1198}
}
@article{PhysRev.52.1003,
  title = {New Evidence for the Existence of a Particle of Mass Intermediate Between the Proton and Electron},
  author = {Street, J. C. and Stevenson, E. C.},
  journal = {Phys. Rev.},
  volume = {52},
  issue = {9},
  pages = {1003--1004},
  numpages = {0},
  year = {1937},
  month = {Nov},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRev.52.1003},
  url = {https://link.aps.org/doi/10.1103/PhysRev.52.1003}
}






