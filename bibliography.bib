
@article{butter_how_2019,
	title = {How to {GAN} {LHC} Events},
	volume = {7},
	issn = {2542-4653},
	url = {http://arxiv.org/abs/1907.03764},
	doi = {10.21468/SciPostPhys.7.6.075},
	abstract = {Event generation for the {LHC} can be supplemented by generative adversarial networks, which generate physical events and avoid highly ineﬃcient event unweighting. For top pair production we show how such a network describes intermediate on-shell particles, phase space boundaries, and tails of distributions. In particular, we introduce the maximum mean discrepancy to resolve sharp local features. It can be extended in a straightforward manner to include for instance oﬀ-shell contributions, higher orders, or approximate detector effects.},
	pages = {075},
	number = {6},
	journaltitle = {{SciPost} Physics},
	shortjournal = {{SciPost} Phys.},
	author = {Butter, Anja and Plehn, Tilman and Winterhalder, Ramon},
	urldate = {2021-01-12},
	date = {2019-12-04},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1907.03764},
	keywords = {High Energy Physics - Phenomenology},
	file = {Butter et al. - 2019 - How to GAN LHC Events.pdf:/home/md618/Zotero/storage/ESDDXS8J/Butter et al. - 2019 - How to GAN LHC Events.pdf:application/pdf},
}

@article{matchev_uncertainties_2020,
	title = {Uncertainties associated with {GAN}-generated datasets in high energy physics},
	url = {http://arxiv.org/abs/2002.06307},
	abstract = {Recently, Generative Adversarial Networks ({GANs}) trained on samples of traditionally simulated collider events have been proposed as a way of generating larger simulated datasets at a reduced computational cost. In this paper we present an argument cautioning against the usage of this method to meet the simulation requirements of an experiment, namely that data generated by a {GAN} cannot statistically be better than the data it was trained on.},
	journaltitle = {{arXiv}:2002.06307 [hep-ex, physics:hep-ph, physics:physics]},
	author = {Matchev, Konstantin T. and Shyamsundar, Prasanth},
	urldate = {2021-01-12},
	date = {2020-05-29},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2002.06307},
	keywords = {High Energy Physics - Phenomenology, High Energy Physics - Experiment, Physics - Computational Physics, Physics - Data Analysis, Statistics and Probability},
	file = {Matchev and Shyamsundar - 2020 - Uncertainties associated with GAN-generated datase.pdf:/home/md618/Zotero/storage/UNZ83PZS/Matchev and Shyamsundar - 2020 - Uncertainties associated with GAN-generated datase.pdf:application/pdf},
}
@inproceedings{NIPS2017_892c3b1c,
 author = {Gulrajani, Ishaan and Ahmed, Faruk and Arjovsky, Martin and Dumoulin, Vincent and Courville, Aaron C},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Improved Training of Wasserstein GANs},
 url = {https://proceedings.neurips.cc/paper/2017/file/892c3b1c6dccd52936e27cbd0ff683d6-Paper.pdf},
 volume = {30},
 year = {2017}
}



@article{karras_progressive_2018,
	title = {Progressive Growing of {GANs} for Improved Quality, Stability, and Variation},
	url = {http://arxiv.org/abs/1710.10196},
	abstract = {We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly ﬁne details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., {CELEBA} images at 10242. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised {CIFAR}10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating {GAN} results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the {CELEBA} dataset.},
	journaltitle = {{arXiv}:1710.10196 [cs, stat]},
	author = {Karras, Tero and Aila, Timo and Laine, Samuli and Lehtinen, Jaakko},
	urldate = {2021-01-12},
	date = {2018-02-26},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1710.10196},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file = {Karras et al. - 2018 - Progressive Growing of GANs for Improved Quality, .pdf:/home/md618/Zotero/storage/YX5JFKQD/Karras et al. - 2018 - Progressive Growing of GANs for Improved Quality, .pdf:application/pdf},
}

@article{he_deep_2015,
	title = {Deep Residual Learning for Image Recognition},
	url = {http://arxiv.org/abs/1512.03385},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the {ImageNet} dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than {VGG} nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the {ImageNet} test set. This result won the 1st place on the {ILSVRC} 2015 classification task. We also present analysis on {CIFAR}-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the {COCO} object detection dataset. Deep residual nets are foundations of our submissions to {ILSVRC} \& {COCO} 2015 competitions, where we also won the 1st places on the tasks of {ImageNet} detection, {ImageNet} localization, {COCO} detection, and {COCO} segmentation.},
	journaltitle = {{arXiv}:1512.03385 [cs]},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	urldate = {2021-01-12},
	date = {2015-12-10},
	eprinttype = {arxiv},
	eprint = {1512.03385},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/md618/Zotero/storage/RBTA6XG5/He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf:application/pdf;arXiv.org Snapshot:/home/md618/Zotero/storage/XLLX6VM7/1512.html:text/html},
}

@article{qin_how_2020,
	title = {How does Lipschitz Regularization Influence {GAN} Training?},
	url = {http://arxiv.org/abs/1811.09567},
	abstract = {Despite the success of Lipschitz regularization in stabilizing {GAN} training, the exact reason of its effectiveness remains poorly understood. The direct effect of \$K\$-Lipschitz regularization is to restrict the \$L2\$-norm of the neural network gradient to be smaller than a threshold \$K\$ (e.g., \$K=1\$) such that \${\textbackslash}{\textbar}{\textbackslash}nabla f{\textbackslash}{\textbar} {\textbackslash}leq K\$. In this work, we uncover an even more important effect of Lipschitz regularization by examining its impact on the loss function: It degenerates {GAN} loss functions to almost linear ones by restricting their domain and interval of attainable gradient values. Our analysis shows that loss functions are only successful if they are degenerated to almost linear ones. We also show that loss functions perform poorly if they are not degenerated and that a wide range of functions can be used as loss function as long as they are sufficiently degenerated by regularization. Basically, Lipschitz regularization ensures that all loss functions effectively work in the same way. Empirically, we verify our proposition on the {MNIST}, {CIFAR}10 and {CelebA} datasets.},
	journaltitle = {{arXiv}:1811.09567 [cs]},
	author = {Qin, Yipeng and Mitra, Niloy and Wonka, Peter},
	urldate = {2021-01-12},
	date = {2020-08-25},
	eprinttype = {arxiv},
	eprint = {1811.09567},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/md618/Zotero/storage/QXNNRHEK/Qin et al. - 2020 - How does Lipschitz Regularization Influence GAN Tr.pdf:application/pdf;arXiv.org Snapshot:/home/md618/Zotero/storage/IG5Y3TYK/1811.html:text/html},
}

@article{xu_modeling_2019,
	title = {Modeling Tabular data using Conditional {GAN}},
	url = {http://arxiv.org/abs/1907.00503},
	abstract = {Modeling the probability distribution of rows in tabular data and generating realistic synthetic data is a non-trivial task. Tabular data usually contains a mix of discrete and continuous columns. Continuous columns may have multiple modes whereas discrete columns are sometimes imbalanced making the modeling difficult. Existing statistical and deep neural network models fail to properly model this type of data. We design {TGAN}, which uses a conditional generative adversarial network to address these challenges. To aid in a fair and thorough comparison, we design a benchmark with 7 simulated and 8 real datasets and several Bayesian network baselines. {TGAN} outperforms Bayesian methods on most of the real datasets whereas other deep learning methods could not.},
	journaltitle = {{arXiv}:1907.00503 [cs, stat]},
	author = {Xu, Lei and Skoularidou, Maria and Cuesta-Infante, Alfredo and Veeramachaneni, Kalyan},
	urldate = {2021-01-12},
	date = {2019-10-27},
	eprinttype = {arxiv},
	eprint = {1907.00503},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/md618/Zotero/storage/BBJVRSKM/Xu et al. - 2019 - Modeling Tabular data using Conditional GAN.pdf:application/pdf;arXiv.org Snapshot:/home/md618/Zotero/storage/3Y9BLDV2/1907.html:text/html},
}

@article{he_delving_2015,
	title = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on {ImageNet} Classification},
	url = {http://arxiv.org/abs/1502.01852},
	shorttitle = {Delving Deep into Rectifiers},
	abstract = {Rectified activation units (rectifiers) are essential for state-of-the-art neural networks. In this work, we study rectifier neural networks for image classification from two aspects. First, we propose a Parametric Rectified Linear Unit ({PReLU}) that generalizes the traditional rectified unit. {PReLU} improves model fitting with nearly zero extra computational cost and little overfitting risk. Second, we derive a robust initialization method that particularly considers the rectifier nonlinearities. This method enables us to train extremely deep rectified models directly from scratch and to investigate deeper or wider network architectures. Based on our {PReLU} networks ({PReLU}-nets), we achieve 4.94\% top-5 test error on the {ImageNet} 2012 classification dataset. This is a 26\% relative improvement over the {ILSVRC} 2014 winner ({GoogLeNet}, 6.66\%). To our knowledge, our result is the first to surpass human-level performance (5.1\%, Russakovsky et al.) on this visual recognition challenge.},
	journaltitle = {{arXiv}:1502.01852 [cs]},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	urldate = {2021-01-12},
	date = {2015-02-06},
	eprinttype = {arxiv},
	eprint = {1502.01852},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/md618/Zotero/storage/DIZJ6EBQ/He et al. - 2015 - Delving Deep into Rectifiers Surpassing Human-Lev.pdf:application/pdf;arXiv.org Snapshot:/home/md618/Zotero/storage/ERSNSTRF/1502.html:text/html},
}

@article{fedus_many_2018,
	title = {Many Paths to Equilibrium: {GANs} Do Not Need to Decrease a Divergence At Every Step},
	url = {http://arxiv.org/abs/1710.08446},
	shorttitle = {Many Paths to Equilibrium},
	abstract = {Generative adversarial networks ({GANs}) are a family of generative models that do not minimize a single training criterion. Unlike other generative models, the data distribution is learned via a game between a generator (the generative model) and a discriminator (a teacher providing training signal) that each minimize their own cost. {GANs} are designed to reach a Nash equilibrium at which each player cannot reduce their cost without changing the other players' parameters. One useful approach for the theory of {GANs} is to show that a divergence between the training distribution and the model distribution obtains its minimum value at equilibrium. Several recent research directions have been motivated by the idea that this divergence is the primary guide for the learning process and that every step of learning should decrease the divergence. We show that this view is overly restrictive. During {GAN} training, the discriminator provides learning signal in situations where the gradients of the divergences between distributions would not be useful. We provide empirical counterexamples to the view of {GAN} training as divergence minimization. Specifically, we demonstrate that {GANs} are able to learn distributions in situations where the divergence minimization point of view predicts they would fail. We also show that gradient penalties motivated from the divergence minimization perspective are equally helpful when applied in other contexts in which the divergence minimization perspective does not predict they would be helpful. This contributes to a growing body of evidence that {GAN} training may be more usefully viewed as approaching Nash equilibria via trajectories that do not necessarily minimize a specific divergence at each step.},
	journaltitle = {{arXiv}:1710.08446 [cs, stat]},
	author = {Fedus, William and Rosca, Mihaela and Lakshminarayanan, Balaji and Dai, Andrew M. and Mohamed, Shakir and Goodfellow, Ian},
	urldate = {2021-01-12},
	date = {2018-02-20},
	eprinttype = {arxiv},
	eprint = {1710.08446},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/md618/Zotero/storage/CG3ZR985/Fedus et al. - 2018 - Many Paths to Equilibrium GANs Do Not Need to Dec.pdf:application/pdf;arXiv.org Snapshot:/home/md618/Zotero/storage/AUT3VS2T/1710.html:text/html},
}

@article{karras_style-based_2019,
	title = {A Style-Based Generator Architecture for Generative Adversarial Networks},
	url = {http://arxiv.org/abs/1812.04948},
	abstract = {We propose an alternative generator architecture for generative adversarial networks, borrowing from style transfer literature. The new architecture leads to an automatically learned, unsupervised separation of high-level attributes (e.g., pose and identity when trained on human faces) and stochastic variation in the generated images (e.g., freckles, hair), and it enables intuitive, scale-specific control of the synthesis. The new generator improves the state-of-the-art in terms of traditional distribution quality metrics, leads to demonstrably better interpolation properties, and also better disentangles the latent factors of variation. To quantify interpolation quality and disentanglement, we propose two new, automated methods that are applicable to any generator architecture. Finally, we introduce a new, highly varied and high-quality dataset of human faces.},
	journaltitle = {{arXiv}:1812.04948 [cs, stat]},
	author = {Karras, Tero and Laine, Samuli and Aila, Timo},
	urldate = {2021-01-12},
	date = {2019-03-29},
	eprinttype = {arxiv},
	eprint = {1812.04948},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv Fulltext PDF:/home/md618/Zotero/storage/MWT89ETG/Karras et al. - 2019 - A Style-Based Generator Architecture for Generativ.pdf:application/pdf;arXiv.org Snapshot:/home/md618/Zotero/storage/CEJIG2E5/1812.html:text/html},
}

@article{salimans_improved_2016,
	title = {Improved Techniques for Training {GANs}},
	url = {http://arxiv.org/abs/1606.03498},
	abstract = {We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks ({GANs}) framework. We focus on two applications of {GANs}: semi-supervised learning, and the generation of images that humans find visually realistic. Unlike most work on generative models, our primary goal is not to train a model that assigns high likelihood to test data, nor do we require the model to be able to learn well without using any labels. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on {MNIST}, {CIFAR}-10 and {SVHN}. The generated images are of high quality as confirmed by a visual Turing test: our model generates {MNIST} samples that humans cannot distinguish from real data, and {CIFAR}-10 samples that yield a human error rate of 21.3\%. We also present {ImageNet} samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of {ImageNet} classes.},
	journaltitle = {{arXiv}:1606.03498 [cs]},
	author = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
	urldate = {2021-01-12},
	date = {2016-06-10},
	eprinttype = {arxiv},
	eprint = {1606.03498},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/md618/Zotero/storage/4LSFHM6R/Salimans et al. - 2016 - Improved Techniques for Training GANs.pdf:application/pdf;arXiv.org Snapshot:/home/md618/Zotero/storage/PVPYXSCB/1606.html:text/html},
}

@online{sahoo_residual_2018,
	title = {Residual blocks — Building blocks of {ResNet}},
	url = {https://towardsdatascience.com/residual-blocks-building-blocks-of-resnet-fd90ca15d6ec},
	abstract = {Understanding  a residual block is quite easy. In traditional neural networks, each layer feeds into the next layer. In a network with…},
	titleaddon = {Medium},
	author = {Sahoo, Sabyasachi},
	urldate = {2021-01-12},
	date = {2018-11-29},
	langid = {english},
	file = {Snapshot:/home/md618/Zotero/storage/94FTKW7Q/residual-blocks-building-blocks-of-resnet-fd90ca15d6ec.html:text/html},
}

@article{camino_generating_2018,
	title = {Generating Multi-Categorical Samples with Generative Adversarial Networks},
	url = {http://arxiv.org/abs/1807.01202},
	abstract = {We propose a method to train generative adversarial networks on mutivariate feature vectors representing multiple categorical values. In contrast to the continuous domain, where {GAN}-based methods have delivered considerable results, {GANs} struggle to perform equally well on discrete data. We propose and compare several architectures based on multiple (Gumbel) softmax output layers taking into account the structure of the data. We evaluate the performance of our architecture on datasets with different sparsity, number of features, ranges of categorical values, and dependencies among the features. Our proposed architecture and method outperforms existing models.},
	journaltitle = {{arXiv}:1807.01202 [cs, stat]},
	author = {Camino, Ramiro and Hammerschmidt, Christian and State, Radu},
	urldate = {2021-01-12},
	date = {2018-07-04},
	eprinttype = {arxiv},
	eprint = {1807.01202},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/md618/Zotero/storage/TVBJ6R94/Camino et al. - 2018 - Generating Multi-Categorical Samples with Generati.pdf:application/pdf;arXiv.org Snapshot:/home/md618/Zotero/storage/4SYPH4LA/1807.html:text/html},
}

@online{bai_comprehensive_2019,
	title = {A Comprehensive Introduction to Different Types of Convolutions in Deep Learning},
	url = {https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215},
	abstract = {Towards intuitive understanding of convolutions through visualizations},
	titleaddon = {Medium},
	author = {Bai, Kunlun},
	urldate = {2021-01-12},
	date = {2019-02-11},
	langid = {english},
}

@article{miyato_spectral_2018,
	title = {Spectral Normalization for Generative Adversarial Networks},
	url = {http://arxiv.org/abs/1802.05957},
	abstract = {One of the challenges in the study of generative adversarial networks is the instability of its training. In this paper, we propose a novel weight normalization technique called spectral normalization to stabilize the training of the discriminator. Our new normalization technique is computationally light and easy to incorporate into existing implementations. We tested the efficacy of spectral normalization on {CIFAR}10, {STL}-10, and {ILSVRC}2012 dataset, and we experimentally confirmed that spectrally normalized {GANs} ({SN}-{GANs}) is capable of generating images of better or equal quality relative to the previous training stabilization techniques.},
	journaltitle = {{arXiv}:1802.05957 [cs, stat]},
	author = {Miyato, Takeru and Kataoka, Toshiki and Koyama, Masanori and Yoshida, Yuichi},
	urldate = {2021-01-12},
	date = {2018-02-16},
	eprinttype = {arxiv},
	eprint = {1802.05957},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/md618/Zotero/storage/IR7ZBE7F/Miyato et al. - 2018 - Spectral Normalization for Generative Adversarial .pdf:application/pdf;arXiv.org Snapshot:/home/md618/Zotero/storage/YTUJFK3I/1802.html:text/html},
}

@inproceedings{wang_multiscale_2003,
	location = {Pacific Grove, {CA}, {USA}},
	title = {Multiscale structural similarity for image quality assessment},
	isbn = {978-0-7803-8104-9},
	url = {http://ieeexplore.ieee.org/document/1292216/},
	doi = {10.1109/ACSSC.2003.1292216},
	abstract = {The structural similarity image quality paradigm is based on the assumption that the human visual system is highly adapted for extracting structural information from the scene, and therefore a measure of structural similarity can provide a good approximation to perceived image quality. This paper proposes a multi-scale structural similarity method, which supplies more ﬂexibility than previous single-scale methods in incorporating the variations of viewing conditions. We develop an image synthesis method to calibrate the parameters that deﬁne the relative importance of different scales. Experimental comparisons demonstrate the effectiveness of the proposed method.},
	eventtitle = {Conference Record of the 37th Asilomar Conference on Signals, Systems and Computers},
	pages = {1398--1402},
	booktitle = {The Thrity-Seventh Asilomar Conference on Signals, Systems \& Computers, 2003},
	publisher = {{IEEE}},
	author = {Wang, Z. and Simoncelli, E.P. and Bovik, A.C.},
	urldate = {2021-01-12},
	date = {2003},
	langid = {english},
	file = {Wang et al. - 2003 - Multiscale structural similarity for image quality.pdf:/home/md618/Zotero/storage/QILE2AAZ/Wang et al. - 2003 - Multiscale structural similarity for image quality.pdf:application/pdf},
}

@article{barua_fcc-gan_2019,
	title = {{FCC}-{GAN}: A Fully Connected and Convolutional Net Architecture for {GANs}},
	url = {http://arxiv.org/abs/1905.02417},
	shorttitle = {{FCC}-{GAN}},
	abstract = {Generative Adversarial Networks ({GANs}) are a powerful class of generative models. Despite their successes, the most appropriate choice of a {GAN} network architecture is still not well understood. {GAN} models for image synthesis have adopted a deep convolutional network architecture, which eliminates or minimizes the use of fully connected and pooling layers in favor of convolution layers in the generator and discriminator of {GANs}. In this paper, we demonstrate that a convolution network architecture utilizing deep fully connected layers and pooling layers can be more effective than the traditional convolution-only architecture, and we propose {FCC}-{GAN}, a fully connected and convolutional {GAN} architecture. Models based on our {FCC}-{GAN} architecture learn both faster than the conventional architecture and also generate higher quality of samples. We demonstrate the effectiveness and stability of our approach across four popular image datasets.},
	journaltitle = {{arXiv}:1905.02417 [cs, stat]},
	author = {Barua, Sukarna and Erfani, Sarah Monazam and Bailey, James},
	urldate = {2021-01-12},
	date = {2019-05-27},
	eprinttype = {arxiv},
	eprint = {1905.02417},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/md618/Zotero/storage/FDLP27WC/Barua et al. - 2019 - FCC-GAN A Fully Connected and Convolutional Net A.pdf:application/pdf;arXiv.org Snapshot:/home/md618/Zotero/storage/BC2J6GF4/1905.html:text/html},
}

@online{noauthor_towards_nodate,
	title = {Towards Data Set Augmentation With {GANs}},
	url = {https://www.jungle.ai/post/towards-data-set-augmentation-with-gans},
	urldate = {2021-01-12},
}

@online{noauthor_rmachinelearning_nodate,
	title = {r/{MachineLearning} - [D] Why do we use gumbel softmax instead of simple softmax for discrete cases?},
	url = {https://www.reddit.com/r/MachineLearning/comments/7fowm7/d_why_do_we_use_gumbel_softmax_instead_of_simple/},
	abstract = {17 votes and 9 comments so far on Reddit},
	titleaddon = {reddit},
	urldate = {2021-01-12},
	langid = {american},
	file = {Snapshot:/home/md618/Zotero/storage/ZNU8XBDJ/d_why_do_we_use_gumbel_softmax_instead_of_simple.html:text/html},
}

@article{paganini_calogan_2018,
	title = {{CaloGAN}: Simulating 3D High Energy Particle Showers in Multi-Layer Electromagnetic Calorimeters with Generative Adversarial Networks},
	volume = {97},
	issn = {2470-0010, 2470-0029},
	url = {http://arxiv.org/abs/1712.10321},
	doi = {10.1103/PhysRevD.97.014021},
	shorttitle = {{CaloGAN}},
	abstract = {The precise modeling of subatomic particle interactions and propagation through matter is paramount for the advancement of nuclear and particle physics searches and precision measurements. The most computationally expensive step in the simulation pipeline of a typical experiment at the Large Hadron Collider ({LHC}) is the detailed modeling of the full complexity of physics processes that govern the motion and evolution of particle showers inside calorimeters. We introduce {\textbackslash}textsc\{{CaloGAN}\}, a new fast simulation technique based on generative adversarial networks ({GANs}). We apply these neural networks to the modeling of electromagnetic showers in a longitudinally segmented calorimeter, and achieve speedup factors comparable to or better than existing full simulation techniques on {CPU} (\$100{\textbackslash}times\$-\$1000{\textbackslash}times\$) and even faster on {GPU} (up to \${\textbackslash}sim10{\textasciicircum}5{\textbackslash}times\$). There are still challenges for achieving precision across the entire phase space, but our solution can reproduce a variety of geometric shower shape properties of photons, positrons and charged pions. This represents a significant stepping stone toward a full neural network-based detector simulation that could save significant computing time and enable many analyses now and in the future.},
	pages = {014021},
	number = {1},
	journaltitle = {Physical Review D},
	shortjournal = {Phys. Rev. D},
	author = {Paganini, Michela and de Oliveira, Luke and Nachman, Benjamin},
	urldate = {2021-01-13},
	date = {2018-01-30},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1712.10321},
	keywords = {High Energy Physics - Phenomenology, High Energy Physics - Experiment, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Paganini et al. - 2018 - CaloGAN Simulating 3D High Energy Particle Shower.pdf:/home/md618/Zotero/storage/XEJQVCNE/Paganini et al. - 2018 - CaloGAN Simulating 3D High Energy Particle Shower.pdf:application/pdf},
}

@article{erdmann_precise_2019,
	title = {Precise simulation of electromagnetic calorimeter showers using a Wasserstein Generative Adversarial Network},
	volume = {3},
	issn = {2510-2036, 2510-2044},
	url = {http://arxiv.org/abs/1807.01954},
	doi = {10.1007/s41781-018-0019-7},
	abstract = {Simulations of particle showers in calorimeters are computationally time-consuming, as they have to reproduce both energy depositions and their considerable fluctuations. A new approach to ultra-fast simulations are generative models where all calorimeter energy depositions are generated simultaneously. We use {GEANT}4 simulations of an electron beam impinging on a multi-layer electromagnetic calorimeter for adversarial training of a generator network and a critic network guided by the Wasserstein distance. The generator is constraint during the training such that the generated showers show the expected dependency on the initial energy and the impact position. It produces realistic calorimeter energy depositions, fluctuations and correlations which we demonstrate in distributions of typical calorimeter observables. In most aspects, we observe that generated calorimeter showers reach the level of showers as simulated with the {GEANT}4 program.},
	pages = {4},
	number = {1},
	journaltitle = {Computing and Software for Big Science},
	shortjournal = {Comput Softw Big Sci},
	author = {Erdmann, Martin and Glombitza, Jonas and Quast, Thorben},
	urldate = {2021-01-13},
	date = {2019-12},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1807.01954},
	keywords = {High Energy Physics - Experiment, Physics - Instrumentation and Detectors},
	file = {Erdmann et al. - 2019 - Precise simulation of electromagnetic calorimeter .pdf:/home/md618/Zotero/storage/E64JV7V5/Erdmann et al. - 2019 - Precise simulation of electromagnetic calorimeter .pdf:application/pdf},
}

@article{otten_event_2019,
	title = {Event Generation and Statistical Sampling for Physics with Deep Generative Models and a Density Information Buffer},
	url = {http://arxiv.org/abs/1901.00875},
	abstract = {We present a study for the generation of events from a physical process with deep generative models. The simulation of physical processes requires not only the production of physical events, but also to ensure these events occur with the correct frequencies. We investigate the feasibility of learning the event generation and the frequency of occurrence with Generative Adversarial Networks ({GANs}) and Variational Autoencoders ({VAEs}) to produce events like Monte Carlo generators. We study three processes: a simple two-body decay, the processes \$e{\textasciicircum}+e{\textasciicircum}-{\textbackslash}to Z {\textbackslash}to l{\textasciicircum}+l{\textasciicircum}-\$ and \$p p {\textbackslash}to t{\textbackslash}bar\{t\} \$ including the decay of the top quarks and a simulation of the detector response. We find that the tested {GAN} architectures and the standard {VAE} are not able to learn the distributions precisely. By buffering density information of encoded Monte Carlo events given the encoder of a {VAE} we are able to construct a prior for the sampling of new events from the decoder that yields distributions that are in very good agreement with real Monte Carlo events and are generated several orders of magnitude faster. Applications of this work include generic density estimation and sampling, targeted event generation via a principal component analysis of encoded ground truth data, anomaly detection and more efficient importance sampling, e.g. for the phase space integration of matrix elements in quantum field theories.},
	journaltitle = {{arXiv}:1901.00875 [hep-ex, physics:hep-ph, physics:physics]},
	author = {Otten, Sydney and Caron, Sascha and de Swart, Wieske and van Beekveld, Melissa and Hendriks, Luc and van Leeuwen, Caspar and Podareanu, Damian and de Austri, Roberto Ruiz and Verheyen, Rob},
	urldate = {2021-01-13},
	date = {2019-12-04},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1901.00875},
	keywords = {High Energy Physics - Phenomenology, High Energy Physics - Experiment, Physics - Data Analysis, Statistics and Probability},
	file = {Otten et al. - 2019 - Event Generation and Statistical Sampling for Phys.pdf:/home/md618/Zotero/storage/9F3FXURZ/Otten et al. - 2019 - Event Generation and Statistical Sampling for Phys.pdf:application/pdf},
}

@online{noauthor_what_nodate,
	title = {What are temporal convolutional neural networks?},
	url = {https://www.quora.com/What-are-temporal-convolutional-neural-networks},
	abstract = {Answer: Temporal Convolutional Networks, or simply {TCN} is a variation over Convolutional Neural Networks for sequence modelling tasks. Rather, it’s quite a descriptive term for a family of architectures.

Motivation:

 * {TCNs} exhibit longer memory than recurrent architectures with the same capaci...},
	titleaddon = {Quora},
	urldate = {2021-01-15},
	langid = {english},
	file = {Snapshot:/home/md618/Zotero/storage/SILS4YTB/What-are-temporal-convolutional-neural-networks.html:text/html},
}

@article{choi_generating_2018,
	title = {Generating Multi-label Discrete Patient Records using Generative Adversarial Networks},
	url = {http://arxiv.org/abs/1703.06490},
	abstract = {Access to electronic health record ({EHR}) data has motivated computational advances in medical research. However, various concerns, particularly over privacy, can limit access to and collaborative use of {EHR} data. Sharing synthetic {EHR} data could mitigate risk.},
	journaltitle = {{arXiv}:1703.06490 [cs]},
	author = {Choi, Edward and Biswal, Siddharth and Malin, Bradley and Duke, Jon and Stewart, Walter F. and Sun, Jimeng},
	urldate = {2021-01-19},
	date = {2018-01-11},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1703.06490},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file = {Choi et al. - 2018 - Generating Multi-label Discrete Patient Records us.pdf:/home/md618/Zotero/storage/D9ILUI9N/Choi et al. - 2018 - Generating Multi-label Discrete Patient Records us.pdf:application/pdf},
}

@article{brenninkmeijer_generation_nodate,
	title = {On the Generation and Evaluation of Tabular Data using {GANs}},
	pages = {70},
	author = {Brenninkmeijer, Bauke},
	langid = {english},
	file = {Brenninkmeijer - On the Generation and Evaluation of Tabular Data u.pdf:/home/md618/Zotero/storage/3GK5DWGL/Brenninkmeijer - On the Generation and Evaluation of Tabular Data u.pdf:application/pdf},
}

@online{noauthor_neural_nodate,
	title = {neural network - Gumbel-Softmax trick vs Softmax with temperature},
	url = {https://datascience.stackexchange.com/questions/58376/gumbel-softmax-trick-vs-softmax-with-temperature},
	titleaddon = {Data Science Stack Exchange},
	urldate = {2021-01-20},
}

@article{kurach_large-scale_nodate,
	title = {A Large-Scale Study on Regularization and Normalization in {GANs}},
	abstract = {Generative adversarial networks ({GANs}) are a class of deep generative models which aim to learn a target distribution in an unsupervised fashion. While they were successfully applied to many problems, training a {GAN} is a notoriously challenging task and requires a signiﬁcant number of hyperparameter tuning, neural architecture engineering, and a non-trivial amount of “tricks”. The success in many practical applications coupled with the lack of a measure to quantify the failure modes of {GANs} resulted in a plethora of proposed losses, regularization and normalization schemes, as well as neural architectures. In this work we take a sober view of the current state of {GANs} from a practical perspective. We discuss and evaluate common pitfalls and reproducibility issues, open-source our code on Github, and provide pre-trained models on {TensorFlow} Hub.},
	pages = {10},
	author = {Kurach, Karol and Lucic, Mario and Zhai, Xiaohua and Michalski, Marcin and Gelly, Sylvain},
	langid = {english},
	file = {Kurach et al. - A Large-Scale Study on Regularization and Normaliz.pdf:/home/md618/Zotero/storage/MSAF4BNE/Kurach et al. - A Large-Scale Study on Regularization and Normaliz.pdf:application/pdf},
}

@article{buhmann_getting_2020,
	title = {Getting High: High Fidelity Simulation of High Granularity Calorimeters with High Speed},
	url = {http://arxiv.org/abs/2005.05334},
	shorttitle = {Getting High},
	abstract = {Accurate simulation of physical processes is crucial for the success of modern particle physics. However, simulating the development and interaction of particle showers with calorimeter detectors is a time consuming process and drives the computing needs of large experiments at the {LHC} and future colliders. Recently, generative machine learning models based on deep neural networks have shown promise in speeding up this task by several orders of magnitude. We investigate the use of a new architecture — the Bounded Information Bottleneck Autoencoder — for modelling electromagnetic showers in the central region of the {SiliconTungsten} calorimeter of the proposed International Large Detector. Combined with a novel second post-processing network, this approach achieves an accurate simulation of diﬀerential distributions including for the ﬁrst time the shape of the minimum-ionizing-particle peak compared to a full {GEANT}4 simulation for a highgranularity calorimeter with 27k simulated channels. The results are validated by comparing to established architectures. Our results further strengthen the case of using generative networks for fast simulation and demonstrate that physically relevant diﬀerential distributions can be described with high accuracy.},
	journaltitle = {{arXiv}:2005.05334 [hep-ex, physics:hep-ph, physics:physics]},
	author = {Buhmann, Erik and Diefenbacher, Sascha and Eren, Engin and Gaede, Frank and Kasieczka, Gregor and Korol, Anatolii and Krüger, Katja},
	urldate = {2021-01-23},
	date = {2020-07-20},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2005.05334},
	keywords = {High Energy Physics - Phenomenology, High Energy Physics - Experiment, Physics - Data Analysis, Statistics and Probability, Physics - Instrumentation and Detectors},
	file = {Buhmann et al. - 2020 - Getting High High Fidelity Simulation of High Gra.pdf:/home/md618/Zotero/storage/HVBARYFF/Buhmann et al. - 2020 - Getting High High Fidelity Simulation of High Gra.pdf:application/pdf},
}

@article{loshchilov_decoupled_2019,
	title = {Decoupled Weight Decay Regularization},
	url = {http://arxiv.org/abs/1711.05101},
	abstract = {L\$\_2\$ regularization and weight decay regularization are equivalent for standard stochastic gradient descent (when rescaled by the learning rate), but as we demonstrate this is {\textbackslash}emph\{not\} the case for adaptive gradient algorithms, such as Adam. While common implementations of these algorithms employ L\$\_2\$ regularization (often calling it "weight decay" in what may be misleading due to the inequivalence we expose), we propose a simple modification to recover the original formulation of weight decay regularization by {\textbackslash}emph\{decoupling\} the weight decay from the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard {SGD} and Adam and (ii) substantially improves Adam's generalization performance, allowing it to compete with {SGD} with momentum on image classification datasets (on which it was previously typically outperformed by the latter). Our proposed decoupled weight decay has already been adopted by many researchers, and the community has implemented it in {TensorFlow} and {PyTorch}; the complete source code for our experiments is available at https://github.com/loshchil/{AdamW}-and-{SGDW}},
	journaltitle = {{arXiv}:1711.05101 [cs, math]},
	author = {Loshchilov, Ilya and Hutter, Frank},
	urldate = {2021-01-23},
	date = {2019-01-04},
	eprinttype = {arxiv},
	eprint = {1711.05101},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Optimization and Control},
	file = {arXiv Fulltext PDF:/home/md618/Zotero/storage/2YN6GH9Q/Loshchilov and Hutter - 2019 - Decoupled Weight Decay Regularization.pdf:application/pdf;arXiv.org Snapshot:/home/md618/Zotero/storage/DL9L6LCL/1711.html:text/html},
}

@article{cote_synthesizing_2020,
	title = {Synthesizing Property \& Casualty Ratemaking Datasets using Generative Adversarial Networks},
	url = {http://arxiv.org/abs/2008.06110},
	abstract = {Due to conﬁdentiality issues, it can be diﬃcult to access or share interesting datasets for methodological development in actuarial science, or other ﬁelds where personal data are important. We show how to design three diﬀerent types of generative adversarial networks ({GANs}) that can build a synthetic insurance dataset from a conﬁdential original dataset. The goal is to obtain synthetic data that no longer contains sensitive information but still has the same structure as the original dataset and retains the multivariate relationships. In order to adequately model the speciﬁc characteristics of insurance data, we use {GAN} architectures adapted for multi-categorical data: a Wassertein {GAN} with gradient penalty ({MC}-{WGAN}-{GP}), a conditional tabular {GAN} ({CTGAN}) and a Mixed Numerical and Categorical Diﬀerentially Private {GAN} ({MNCDP}-{GAN}). For transparency, the approaches are illustrated using a public dataset, the French motor third party liability data. We compare the three diﬀerent {GANs} on various aspects: ability to reproduce the original data structure and predictive models, privacy, and ease of use. We ﬁnd that the {MC}-{WGAN}-{GP} synthesizes the best data, the {CTGAN} is the easiest to use, and the {MNCDP}-{GAN} guarantees diﬀerential privacy.},
	journaltitle = {{arXiv}:2008.06110 [cs, stat]},
	author = {Cote, Marie-Pier and Hartman, Brian and Mercier, Olivier and Meyers, Joshua and Cummings, Jared and Harmon, Elijah},
	urldate = {2021-01-24},
	date = {2020-08-13},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2008.06110},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Cote et al. - 2020 - Synthesizing Property & Casualty Ratemaking Datase.pdf:/home/md618/Zotero/storage/YL5GZ9BL/Cote et al. - 2020 - Synthesizing Property & Casualty Ratemaking Datase.pdf:application/pdf},
}

@article{goodfellow_generative_2014,
	title = {Generative Adversarial Networks},
	url = {http://arxiv.org/abs/1406.2661},
	abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
	journaltitle = {{arXiv}:1406.2661 [cs, stat]},
	author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	urldate = {2021-01-25},
	date = {2014-06-10},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1406.2661},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Goodfellow et al. - 2014 - Generative Adversarial Networks.pdf:/home/md618/Zotero/storage/CZCT6NSX/Goodfellow et al. - 2014 - Generative Adversarial Networks.pdf:application/pdf},
}

@article{ahdida_fast_2019,
	title = {Fast simulation of muons produced at the {SHiP} experiment using Generative Adversarial Networks},
	volume = {14},
	issn = {1748-0221},
	url = {https://iopscience.iop.org/article/10.1088/1748-0221/14/11/P11028},
	doi = {10.1088/1748-0221/14/11/P11028},
	pages = {P11028--P11028},
	number = {11},
	journaltitle = {Journal of Instrumentation},
	shortjournal = {J. Inst.},
	author = {Ahdida, C. and Albanese, R. and Alexandrov, A. and Anokhina, A. and Aoki, S. and Arduini, G. and Atkin, E. and Azorskiy, N. and Back, J.J. and Bagulya, A. and Santos, F. Baaltasar Dos and Baranov, A. and Bardou, F. and Barker, G.J. and Battistin, M. and Bauche, J. and Bay, A. and Bayliss, V. and Bencivenni, G. and Berdnikov, A.Y. and Berdnikov, Y.A. and Berezkina, I. and Bertani, M. and Betancourt, C. and Bezshyiko, I. and Bezshyyko, O. and Bick, D. and Bieschke, S. and Blanco, A. and Boehm, J. and Bogomilov, M. and Bondarenko, K. and Bonivento, W.M. and Borburgh, J. and Boyarsky, A. and Brenner, R. and Breton, D. and Brundler, R. and Bruschi, M. and Büscher, V. and Buonaura, A. and Buontempo, S. and Cadeddu, S. and Calcaterra, A. and Calviani, M. and Campanelli, M. and Casolino, M. and Charitonidis, N. and Chau, P. and Chauveau, J. and Chepurnov, A. and Chernyavskiy, M. and Choi, K.-Y. and Chumakov, A. and Ciambrone, P. and Congedo, L. and Cornelis, K. and Cristinziani, M. and Crupano, A. and Dallavalle, G.M. and Datwyler, A. and D'Ambrosio, N. and D'Appollonio, G. and Saraiva, J. De Carvalho and Lellis, G. De and de Magistris, M. and Roeck, A. De and Serio, M. De and Simone, D. De and Dedenko, L. and Dergachev, P. and Crescenzo, A. Di and Marco, N. Di and Dib, C. and Dijkstra, H. and Dipinto, P. and Dmitrenko, V. and Dmitrievskiy, S. and Dougherty, L.A. and Dolmatov, A. and Domenici, D. and Donskov, S. and Drohan, V. and Dubreuil, A. and Ehlert, M. and Enik, T. and Etenko, A. and Fabbri, F. and Fabbri, L. and Fabich, A. and Fedin, O. and Fedotovs, F. and Felici, G. and Ferro-Luzzi, M. and Filippov, K. and Fini, R.A. and Fonte, P. and Franco, C. and Fraser, M. and Fresa, R. and Froeschl, R. and Fukuda, T. and Galati, G. and Gall, J. and Gatignon, L. and Gavrilov, G. and Gentile, V. and Gerlach, S. and Goddard, B. and Golinka-Bezshyyko, L. and Golovatiuk, A. and Golubkov, D. and Golutvin, A. and Gorbounov, P. and Gorbunov, D. and Gorbunov, S. and Gorkavenko, V. and Gornushkin, Y. and Gorshenkov, M. and Grachev, V. and Grandchamp, A.L. and Granich, G. and Graverini, E. and Grenard, J.-L. and Grenier, D. and Grichine, V. and Gruzinskii, N. and Guler, A. M. and Guz, Yu. and Haefeli, G.J. and Hagner, C. and Hakobyan, H. and Harris, I.W. and Herwijnen, E. van and Hessler, C. and Hollnagel, A. and Hosseini, B. and Hushchyn, M. and Iaselli, G. and Iuliano, A. and Ivantchenko, V. and Jacobsson, R. and Joković, D. and Jonker, M. and Kadenko, I. and Kain, V. and Kaiser, B. and Kamiscioglu, C. and Kershaw, K. and Khabibullin, M. and Khalikov, E. and Khaustov, G. and Khoriauli, G. and Khotyantsev, A. and Kim, S.H. and Kim, Y.G. and Kim, V. and Kitagawa, N. and Ko, J.-W. and Kodama, K. and Kolesnikov, A. and Kolev, D.I. and Kolosov, V. and Komatsu, M. and Kondrateva, N. and Kono, A. and Konovalova, N. and Kormannshaus, S. and Korol, I. and Korol'ko, I. and Korzenev, A. and Kostyukhin, V. and Platia, E. Koukovini and Kovalenko, S. and Krasilnikova, I. and Kudenko, Y. and Kurbatov, E. and Kurbatov, P. and Kurochka, V. and Kuznetsova, E. and Lacker, H.M. and Lamont, M. and Lanfranchi, G. and Lantwin, O. and Lauria, A. and Lee, K.S. and Lee, K.Y. and Lévy, J.-M. and Loschiavo, V.P. and Lopes, L. and Sola, E. Lopez and Lyubovitskij, V. and Maalmi, J. and Magnan, A. and Maleev, V. and Malinin, A. and Manabe, Y. and Managadze, A.K. and Manfredi, M. and Marsh, S. and Marshall, A.M. and Mefodev, A. and Mermod, P. and Miano, A. and Mikado, S. and Mikhaylov, Yu. and Milstead, D.A. and Mineev, O. and Montanari, A. and Montesi, M.C. and Morishima, K. and Movchan, S. and Muttoni, Y. and Naganawa, N. and Nakamura, M. and Nakano, T. and Nasybulin, S. and Ninin, P. and Nishio, A. and Novikov, A. and Obinyakov, B. and Ogawa, S. and Okateva, N. and Opitz, B. and Osborne, J. and Ovchynnikov, M. and Owtscharenko, N. and Owen, P.H. and Pacholek, P. and Paoloni, A. and Park, B.D. and Park, S.K. and Pastore, A. and Patel, M. and Pereyma, D. and Perillo-Marcone, A. and Petkov, G.L. and Petridis, K. and Petrov, A. and Podgrudkov, D. and Poliakov, V. and Polukhina, N. and Prieto, J. Prieto and Prokudin, M. and Prota, A. and Quercia, A. and Rademakers, A. and Rakai, A. and Ratnikov, F. and Rawlings, T. and Redi, F. and Ricciardi, S. and Rinaldesi, M. and Rodin, Volodymyr and Rodin, Viktor and Robbe, P. and Cavalcante, A.B. Rodrigues and Roganova, T. and Rokujo, H. and Rosa, G. and Rovelli, T. and Ruchayskiy, O. and Ruf, T. and Samoylenko, V. and Samsonov, V. and Galan, F. Sanchez and Diaz, P. Santos and Ull, A. Sanz and Saputi, A. and Sato, O. and Savchenko, E.S. and Schliwinski, J.S. and Schmidt-Parzefall, W. and Serra, N. and Sgobba, S. and Shadura, O. and Shakin, A. and Shaposhnikov, M. and Shatalov, P. and Shchedrina, T. and Shchutska, L. and Shevchenko, V. and Shibuya, H. and Shihora, L. and Shirobokov, S. and Shustov, A. and Silverstein, S.B. and Simone, S. and Simoniello, R. and Skorokhvatov, M. and Smirnov, S. and Sohn, J.Y. and Sokolenko, A. and Solodko, E. and Starkov, N. and Stoel, L. and Storaci, B. and Stramaglia, M.E. and Sukhonos, D. and Suzuki, Y. and Takahashi, S. and Tastet, J.L. and Teterin, P. and Naing, S. Than and Timiryasov, I. and Tioukov, V. and Tommasini, D. and Torii, M. and Tosi, N. and Treille, D. and Tsenov, R. and Ulin, S. and Ustyuzhanin, A. and Uteshev, Z. and Vankova-Kirilova, G. and Vannucci, F. and Venkova, P. and Venturi, V. and Vilchinski, S. and Villa, M. and Vincke, Heinz and Vincke, Helmut and Visone, C. and Vlasik, K. and Volkov, A. and Voronkov, R. and Waasen, S. van and Wanke, R. and Wertelaers, P. and Woo, J.-K. and Wurm, M. and Xella, S. and Yilmaz, D. and Yilmazer, A.U. and Yoon, C.S. and Zarubin, P. and Zarubina, I. and Zaytsev, Yu.},
	urldate = {2021-01-25},
	date = {2019-11-27},
	langid = {english},
	file = {Ahdida et al. - 2019 - Fast simulation of muons produced at the SHiP expe.pdf:/home/md618/Zotero/storage/ZZK3DMJG/Ahdida et al. - 2019 - Fast simulation of muons produced at the SHiP expe.pdf:application/pdf},
}

@article{butter_how_2020,
	title = {How to {GAN} Event Subtraction},
	url = {http://arxiv.org/abs/1912.08824},
	doi = {10.21468/SciPostPhysCore.3.2.009},
	abstract = {Subtracting event samples is a common task in {LHC} simulation and analysis, and standard solutions tend to be ineﬃcient. We employ generative adversarial networks to produce new event samples with a phase space distribution corresponding to added or subtracted input samples. We ﬁrst illustrate for a toy example how such a network beats the statistical limitations of the training data. We then show how such a network can be used to subtract background events or to include non-local collinear subtraction events at the level of unweighted 4-vector events.},
	journaltitle = {{arXiv}:1912.08824 [hep-ph]},
	author = {Butter, Anja and Plehn, Tilman and Winterhalder, Ramon},
	urldate = {2021-01-25},
	date = {2020-10-14},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1912.08824},
	keywords = {High Energy Physics - Phenomenology},
	file = {Butter et al. - 2020 - How to GAN Event Subtraction.pdf:/home/md618/Zotero/storage/SW73L5SS/Butter et al. - 2020 - How to GAN Event Subtraction.pdf:application/pdf},
}

@article{kendrick_anysize_2020,
	title = {Anysize {GAN}: A solution to the image-warping problem},
	url = {http://arxiv.org/abs/2003.03233},
	shorttitle = {Anysize {GAN}},
	abstract = {We propose a new type of General Adversarial Network ({GAN}) to resolve a common issue with Deep Learning. We develop a novel architecture that can be applied to existing latent vector based {GAN} structures that allows them to generate on-the-ﬂy images of any size. Existing {GAN} for image generation requires uniform images of matching dimensions. However, publicly available datasets, such as {ImageNet} contain thousands of diﬀerent sizes. Resizing image causes deformations and changing the image data, whereas as our network does not require this preprocessing step. We make signiﬁcant changes to the standard data loading techniques to enable any size image to be loaded for training. We also modify the network in two ways, by adding multiple inputs and a novel dynamic resizing layer. Finally we make adjustments to the discriminator to work on multiple resolutions. These changes can allow multiple resolution datasets to be trained on without any resizing, if memory allows. We validate our results on the {ISIC} 2019 skin lesion dataset. We demonstrate our method can successfully generate realistic images at diﬀerent sizes without issue, preserving and understanding spatial relationships, while maintaining feature relationships. We will release the source codes upon paper acceptance.},
	journaltitle = {{arXiv}:2003.03233 [cs, eess]},
	author = {Kendrick, Connah and Gillespie, David and Yap, Moi Hoon},
	urldate = {2021-01-28},
	date = {2020-07-08},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2003.03233},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {Kendrick et al. - 2020 - Anysize GAN A solution to the image-warping probl.pdf:/home/md618/Zotero/storage/RG52SGUI/Kendrick et al. - 2020 - Anysize GAN A solution to the image-warping probl.pdf:application/pdf},
}

@article{de_oliveira_learning_2017,
	title = {Learning Particle Physics by Example: Location-Aware Generative Adversarial Networks for Physics Synthesis},
	volume = {1},
	issn = {2510-2036, 2510-2044},
	url = {http://arxiv.org/abs/1701.05927},
	doi = {10.1007/s41781-017-0004-6},
	shorttitle = {Learning Particle Physics by Example},
	abstract = {We provide a bridge between generative modeling in the Machine Learning community and simulated physical processes in High Energy Particle Physics by applying a novel Generative Adversarial Network ({GAN}) architecture to the production of jet images – 2D representations of energy depositions from particles interacting with a calorimeter. We propose a simple architecture, the Location-Aware Generative Adversarial Network, that learns to produce realistic radiation patterns from simulated high energy particle collisions. The pixel intensities of {GAN}-generated images faithfully span over many orders of magnitude and exhibit the desired low-dimensional physical properties (i.e., jet mass, n-subjettiness, etc.). We shed light on limitations, and provide a novel empirical validation of image quality and validity of {GAN}-produced simulations of the natural world. This work provides a base for further explorations of {GANs} for use in faster simulation in High Energy Particle Physics.},
	pages = {4},
	number = {1},
	journaltitle = {Computing and Software for Big Science},
	shortjournal = {Comput Softw Big Sci},
	author = {de Oliveira, Luke and Paganini, Michela and Nachman, Benjamin},
	urldate = {2021-01-28},
	date = {2017-11},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1701.05927},
	keywords = {High Energy Physics - Experiment, Physics - Data Analysis, Statistics and Probability, Statistics - Machine Learning},
	file = {de Oliveira et al. - 2017 - Learning Particle Physics by Example Location-Awa.pdf:/home/md618/Zotero/storage/VV8LZY5X/de Oliveira et al. - 2017 - Learning Particle Physics by Example Location-Awa.pdf:application/pdf},
}

@article{musella_fast_2018,
	title = {Fast and accurate simulation of particle detectors using generative adversarial networks},
	volume = {2},
	issn = {2510-2036, 2510-2044},
	url = {http://arxiv.org/abs/1805.00850},
	doi = {10.1007/s41781-018-0015-y},
	abstract = {Deep generative models parametrised by neural networks have recently started to provide accurate results in modeling natural images. In particular, generative adversarial networks provide an unsupervised solution to this problem. In this work we apply this kind of technique to the simulation of particle-detector response to hadronic jets. We show that deep neural networks can achieve high-ﬁdelity in this task, while attaining a speed increase of several orders of magnitude with respect to traditional algorithms.},
	pages = {8},
	number = {1},
	journaltitle = {Computing and Software for Big Science},
	shortjournal = {Comput Softw Big Sci},
	author = {Musella, Pasquale and Pandolfi, Francesco},
	urldate = {2021-01-28},
	date = {2018-11},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1805.00850},
	keywords = {High Energy Physics - Phenomenology, High Energy Physics - Experiment, Physics - Data Analysis, Statistics and Probability},
	file = {Musella and Pandolfi - 2018 - Fast and accurate simulation of particle detectors.pdf:/home/md618/Zotero/storage/I4GD2UMW/Musella and Pandolfi - 2018 - Fast and accurate simulation of particle detectors.pdf:application/pdf},
}

@article{erdmann_generating_2018,
	title = {Generating and refining particle detector simulations using the Wasserstein distance in adversarial networks},
	url = {http://arxiv.org/abs/1802.03325},
	abstract = {We use adversarial network architectures together with the Wasserstein distance to generate or reﬁne simulated detector data. The data reﬂect twodimensional projections of spatially distributed signal patterns with a broad spectrum of applications. As an example, we use an observatory to detect cosmic rayinduced air showers with a ground-based array of particle detectors. First we investigate a method of generating detector patterns with variable signal strengths while constraining the primary particle energy. We then present a technique to reﬁne simulated time traces of detectors to match corresponding data distributions. With this method we demonstrate that training a deep network with reﬁned data-like signal traces leads to a more precise energy reconstruction of data events compared to training with the originally simulated traces.},
	journaltitle = {{arXiv}:1802.03325 [astro-ph, physics:hep-ex]},
	author = {Erdmann, Martin and Geiger, Lukas and Glombitza, Jonas and Schmidt, David},
	urldate = {2021-01-29},
	date = {2018-02-09},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1802.03325},
	keywords = {High Energy Physics - Experiment, Astrophysics - Instrumentation and Methods for Astrophysics},
	file = {Erdmann et al. - 2018 - Generating and refining particle detector simulati.pdf:/home/md618/Zotero/storage/BRC7JNRM/Erdmann et al. - 2018 - Generating and refining particle detector simulati.pdf:application/pdf},
}

@article{the_comet_collaboration_comet_2020,
	title = {{COMET} Phase-I technical design report},
	volume = {2020},
	issn = {2050-3911},
	url = {https://academic.oup.com/ptep/article/doi/10.1093/ptep/ptz125/5805094},
	doi = {10.1093/ptep/ptz125},
	abstract = {Abstract
            The Technical Design for the {COMET} Phase-I experiment is presented in this paper. {COMET} is an experiment at J-{PARC}, Japan, which will search for neutrinoless conversion of muons into electrons in the field of an aluminum nucleus (\${\textbackslash}mu\$–\$e\$ conversion, \${\textbackslash}mu{\textasciicircum}\{-\}N {\textbackslash}rightarrow e{\textasciicircum}\{-\}N\$); a lepton flavor-violating process. The experimental sensitivity goal for this process in the Phase-I experiment is \$3.1{\textbackslash}times10{\textasciicircum}\{-15\}\$, or 90\% upper limit of a branching ratio of \$7{\textbackslash}times 10{\textasciicircum}\{-15\}\$, which is a factor of 100 improvement over the existing limit. The expected number of background events is 0.032. To achieve the target sensitivity and background level, the 3.2 {kW} 8 {GeV} proton beam from J-{PARC} will be used. Two types of detectors, {CyDet} and {StrECAL}, will be used for detecting the \${\textbackslash}mu\$–\$e\$ conversion events, and for measuring the beam-related background events in view of the Phase-{II} experiment, respectively. Results from simulation on signal and background estimations are also described.},
	pages = {033C01},
	number = {3},
	journaltitle = {Progress of Theoretical and Experimental Physics},
	author = {{The COMET Collaboration} and Abramishvili, R and Adamov, G and Akhmetshin, R R and Allin, A and Angélique, J C and Anishchik, V and Aoki, M and Aznabayev, D and Bagaturia, I and Ban, G and Ban, Y and Bauer, D and Baygarashev, D and Bondar, A E and Cârloganu, C and Carniol, B and Chau, T T and Chen, J K and Chen, S J and Cheung, Y E and da Silva, W and Dauncey, P D and Densham, C and Devidze, G and Dornan, P and Drutskoy, A and Duginov, V and Eguchi, Y and Epshteyn, L B and Evtoukhovitch, P and Fayer, S and Fedotovich, G V and Finger Jr, M and Finger, M and Fujii, Y and Fukao, Y and Gabriel, J L and Gay, P and Gillies, E and Grigoriev, D N and Gritsay, K and Hai, V H and Hamada, E and Hashim, I H and Hashimoto, S and Hayashi, O and Hayashi, T and Hiasa, T and Ibrahim, Z A and Igarashi, Y and Ignatov, F V and Iio, M and Ishibashi, K and Issadykov, A and Itahashi, T and Jansen, A and Jiang, X S and Jonsson, P and Kachelhoffer, T and Kalinnikov, V and Kaneva, E and Kapusta, F and Katayama, H and Kawagoe, K and Kawashima, R and Kazak, N and Kazanin, V F and Kemularia, O and Khvedelidze, A and Koike, M and Kormoll, T and Kozlov, G A and Kozyrev, A N and Kravchenko, M and Krikler, B and Kumsiashvili, G and Kuno, Y and Kuriyama, Y and Kurochkin, Y and Kurup, A and Lagrange, B and Lai, J and Lee, M J and Li, H B and Litchfield, R P and Li, W G and Loan, T and Lomidze, D and Lomidze, I and Loveridge, P and Macharashvili, G and Makida, Y and Mao, Y J and Markin, O and Matsuda, Y and Melkadze, A and Melnik, A and Mibe, T and Mihara, S and Miyamoto, N and Miyazaki, Y and Mohamad Idris, F and Azmi, K A Mohamed Kamal and Moiseenko, A and Moritsu, M and Mori, Y and Motoishi, T and Nakai, H and Nakai, Y and Nakamoto, T and Nakamura, Y and Nakatsugawa, Y and Nakazawa, Y and Nash, J and Natori, H and Niess, V and Nioradze, M and Nishiguchi, H and Noguchi, K and Numao, T and O’Dell, J and Ogitsu, T and Ohta, S and Oishi, K and Okamoto, K and Okamura, T and Okinaka, K and Omori, C and Ota, T and Pasternak, J and Paulau, A and Picters, D and Ponariadov, V and Quémener, G and Ruban, A A and Rusinov, V and Sabirov, B and Sakamoto, H and Sarin, P and Sasaki, K and Sato, A and Sato, J and Semertzidis, Y K and Shigyo, N and Shoukavy, Dz and Slunecka, M and Stöckinger, D and Sugano, M and Tachimoto, T and Takayanagi, T and Tanaka, M and Tang, J and Tao, C V and Teixeira, A M and Tevzadze, Y and Thanh, T and Tojo, J and Tolmachev, S S and Tomasek, M and Tomizawa, M and Toriashvili, T and Trang, H and Trekov, I and Tsamalaidze, Z and Tsverava, N and Uchida, T and Uchida, Y and Ueno, K and Velicheva, E and Volkov, A and Vrba, V and Abdullah, W A T Wan and Warin-Charpentier, P and Wong, M L and Wong, T S and Wu, C and Xing, T Y and Yamaguchi, H and Yamamoto, A and Yamanaka, M and Yamane, T and Yang, Y and Yano, T and Yao, W C and Yeo, B and Yoshida, H and Yoshida, M and Yoshioka, T and Yuan, Y and Yudin, Yu V and Zdorovets, M V and Zhang, J and Zhang, Y and Zuber, K},
	urldate = {2021-01-29},
	date = {2020-03-01},
	langid = {english},
	file = {The COMET Collaboration et al. - 2020 - COMET Phase-I technical design report.pdf:/home/md618/Zotero/storage/IFDUFLGP/The COMET Collaboration et al. - 2020 - COMET Phase-I technical design report.pdf:application/pdf},
}

@article{Bertl:2006up,
    author = "Bertl, Wilhelm H. and others",
    collaboration = "SINDRUM II",
    title = "{A Search for muon to electron conversion in muonic gold}",
    doi = "10.1140/epjc/s2006-02582-x",
    journal = "Eur. Phys. J. C",
    volume = "47",
    pages = "337--346",
    year = "2006"
}


@article{kansal_graph_2021,
	title = {Graph Generative Adversarial Networks for Sparse Data Generation in High Energy Physics},
	url = {http://arxiv.org/abs/2012.00173},
	abstract = {We develop a graph generative adversarial network to generate sparse data sets like those produced at the {CERN} Large Hadron Collider ({LHC}). We demonstrate this approach by training on and generating sparse representations of {MNIST} handwritten digit images and jets of particles in proton-proton collisions like those at the {LHC}. We find the model successfully generates sparse {MNIST} digits and particle jet data. We quantify agreement between real and generated data with a graph-based Fr{\textbackslash}'echet Inception distance, and the particle and jet feature-level 1-Wasserstein distance for the {MNIST} and jet datasets respectively.},
	journaltitle = {{arXiv}:2012.00173 [hep-ex, physics:hep-ph, physics:physics]},
	author = {Kansal, Raghav and Duarte, Javier and Orzari, Breno and Tomei, Thiago and Pierini, Maurizio and Touranakou, Mary and Vlimant, Jean-Roch and Gunopulos, Dimitrios},
	urldate = {2021-02-03},
	date = {2021-01-30},
	eprinttype = {arxiv},
	eprint = {2012.00173},
	note = {version: 3},
	keywords = {High Energy Physics - Phenomenology, High Energy Physics - Experiment, Physics - Computational Physics, Physics - Data Analysis, Statistics and Probability, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/home/md618/Zotero/storage/LHUHVWWF/Kansal et al. - 2021 - Graph Generative Adversarial Networks for Sparse D.pdf:application/pdf;arXiv.org Snapshot:/home/md618/Zotero/storage/8JAY7ZBX/2012.html:text/html},
}

@article{lin_pacgan_2018,
	title = {{PacGAN}: The power of two samples in generative adversarial networks},
	url = {http://arxiv.org/abs/1712.04086},
	shorttitle = {{PacGAN}},
	abstract = {Generative adversarial networks ({GANs}) are innovative techniques for learning generative models of complex data distributions from samples. Despite remarkable recent improvements in generating realistic images, one of their major shortcomings is the fact that in practice, they tend to produce samples with little diversity, even when trained on diverse datasets. This phenomenon, known as mode collapse, has been the main focus of several recent advances in {GANs}. Yet there is little understanding of why mode collapse happens and why recently proposed approaches are able to mitigate mode collapse. We propose a principled approach to handling mode collapse, which we call packing. The main idea is to modify the discriminator to make decisions based on multiple samples from the same class, either real or artiﬁcially generated. We borrow analysis tools from binary hypothesis testing—in particular the seminal result of Blackwell [6]—to prove a fundamental connection between packing and mode collapse. We show that packing naturally penalizes generators with mode collapse, thereby favoring generator distributions with less mode collapse during the training process. Numerical experiments on benchmark datasets suggests that packing provides signiﬁcant improvements in practice as well.},
	journaltitle = {{arXiv}:1712.04086 [cs, math, stat]},
	author = {Lin, Zinan and Khetan, Ashish and Fanti, Giulia and Oh, Sewoong},
	urldate = {2021-02-04},
	date = {2018-11-02},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1712.04086},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Information Theory},
	file = {Lin et al. - 2018 - PacGAN The power of two samples in generative adv.pdf:/home/md618/Zotero/storage/V7R5U7ER/Lin et al. - 2018 - PacGAN The power of two samples in generative adv.pdf:application/pdf},
}

@inproceedings{45822,
title	= {Categorical Reparameterization with Gumbel-Softmax},
author	= {Eric Jang and Shixiang Gu and Ben Poole},
year	= {2017},
URL	= {https://arxiv.org/abs/1611.01144}
}

